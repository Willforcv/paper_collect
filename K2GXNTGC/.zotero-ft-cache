A General Framework for Lifelong Localization and Mapping in Changing Environment
Min Zhao1, Xin Guo1, Le Song1, Baoxing Qin1, Xuesong Shi2, Gim Hee Lee3, Guanghui Sun4

arXiv:2111.10946v1 [cs.RO] 22 Nov 2021

Abstract— The environment of most real-world scenarios such as malls and supermarkets changes at all times. A prebuilt map that does not account for these changes becomes out-of-date easily. Therefore, it is necessary to have an up-todate model of the environment to facilitate long-term operation of a robot. To this end, this paper presents a general lifelong simultaneous localization and mapping (SLAM) framework. Our framework uses a multiple session map representation, and exploits an efﬁcient map updating strategy that includes map building, pose graph reﬁnement and sparsiﬁcation. To mitigate the unbounded increase of memory usage, we propose a maptrimming method based on the Chow-Liu maximum-mutualinformation spanning tree. The proposed SLAM framework has been comprehensively validated by over a month of robot deployment in real supermarket environment. Furthermore, we release the dataset collected from the indoor and outdoor changing environment with the hope to accelerate lifelong SLAM research in the community. Our dataset is available at https://github.com/sanduan168/lifelong-SLAM-dataset.
I. INTRODUCTION
Accurate and robust localization is one fundamental requirement for robot navigation in complex environments. Fig. 1 shows a service robot working in a dynamic environment of a supermarket. The scenes are full of non-static objects, e.g. doors, goods and containers, which can move anytime. With a static map, conventional scan matching methods [1], [2], [3], [4] may fail easily when a robot traverses through a changing environment. Moreover, the wrong matching result may introduce erroneous loop closure measurements and further leads to catastrophic failures in the back-end optimization [5]. To handle such problems, the robot needs to have the ability to construct and maintain an up-to-date map while it continuously operates in a changing environment. We refer to this as the lifelong Simultaneous Localization and Mapping (SLAM) problem.
A typical SLAM system consists of a front-end and a back-end module [5], [6], [7]. The front-end module collects data such as LIDAR point clouds and camera images from sensors and ﬁnds the transformation between consecutive data frames. The back-end module corrects the front-end estimation drifts by performing the loop closures. In order
*This work was supported in part by the National Key R&D Program of China (No. 2019YFB1312000).
1Gaussian Robotics, Shanghai, China. 2Intel Labs China, Beijing, China. 3Computer Vision and Robotic Perception Lab, Department of Computer Science, School of Computing, National University of Singapore, Singapore. 4Department of Control Science and Engineering, Harbin Institute of Technology, China. 1Author to whom correspondence should be addressed, E-mail, zhaomin@gs-robot.com

Fig. 1. The images above captured from the same perspective at different time.
to tackle environment changes, we introduce a map updating module on top of the front-end and back-end modules. This map updating module performs the following:
• Collect sensor data and record the dynamic scenes while doing localization.
• Detect the differences between old and real-time updated maps.
• Trim the old maps with real-time updated maps, and thus keeping pace with the environment changes under an efﬁcient constant computation complexity.
In this paper, we propose a general framework for lifelong localization and mapping. Speciﬁcally, our framework tracks the changes in the scene and maintains an up-to-date map for accurate and robust localization estimation. We test our method on real commercial robots that operate in a supermarket environment continuously for more than a month. The experiment results show that our method can achieve accurate and robust localization in the presence of signiﬁcant environment changes.
Our main contributions are summarized as follow: • A complete general framework for lifelong SLAM,
which operates effectively in changing environment. • A submap-based graph sparsiﬁcation method that
achieves high accuracy with constant computation and memory complexity. • A public dataset of LIDAR, IMU and wheel encoder data in changing environments for lifelong SLAM.
II. RELATED WORKS
A. Lifelong SLAM
Long-running robots need to consider mapping the changing environment as a life-long process: deleting old nodes and adding new features to update the map [8], [9], [10] and [11]. Biber et al. [8] presents a kind of dynamic map. The key technical contribution is the use of a sample-based representation and its interpretation through robust statistics.

Fig. 2. An overview of the proposed lifelong SLAM framework

The short-term memory map is updated after each localization step and the long-term map is stored and evaluated only after a run or after a day. Walcott et al. [10] presents Dynamic Pose Graph SLAM (DPG-SLAM), an algorithm designed to remove the inactive scans and add the new scans to the map by detecting the label changes after each pass. However, they maintain a pose graph which is comprised of all the scan nodes that will not be optimized in real-time because of high computation complexity. Ding et al. [11] proposes a joint framework for vehicle localization that adaptively incorporate results from both the LiDAR inertial odometry and global matching modules. To overcome the failure of global matching, they also propose an environmental change detection method to ﬁnd out when and what portion of the map should be promptly updated.
In contrast to them, for the purpose of decreasing computational complexity, our method do not include the map change detection module. The map data structure of ours is comprised of several submaps and we replace the old submaps with new ones directly.
B. Pose Graph Sparsiﬁcation
Another task for lifelong SLAM is to sparse the pose graph while minimizing the loss of information when the robots revisit already mapped area. The computation complexity and memory usage should be proportional to the scale of explored space rather than to the localization duration. To this end, pose graph sparsiﬁcation methods are proposed. Kretzschmar et al. [12] uses the expected information gain, which is deﬁned as the expected reduction of uncertainty in the belief of the robot caused by an observation, to reduce the redundant nodes and keep constant size pose graph. In [13], the authors propose the use of a Chow-Liu tree (CLT) [14] to approximate the individual elimination cliques as sparse tree structures and seek to minimize the loss of information, restricting the size of the pose graph. Carlevaris et al. [14] introduces a generic factor-based method for node removal in factor-graph SLAM, which is referred to as generic linear constraint(GLC). It operates on the Markov blanket of a marginalized node and compute a sparse approximation of the blanket. In this work, we combine the CLT sparsiﬁcation

method with submap trimming and resulting in the lifelong SLAM pipeline as below.
III. SYSTEM OVERVIEW
A. System Structure
This section describes the architecture of our proposed framework as shown in Fig. 2. Our system consists of three subsystems: local LiDAR odometry (LLO), global LiDAR matching (GLM) and pose graph reﬁnement (PGR). The role of LLO is the same with [2]: building a succession of submaps which are locally consistent. The GLM subsystem is responsible for calculating the relative constraint between the incoming scans and global submaps, as well as inserting the submaps and constraints into PGR. PGR is the most important part of our system. It collects the submaps from LLO and constraints from GLM, trims the old submaps saved in old session, and executes pose graph sparsiﬁcation and optimization. These modules will be discussed in detail in Section IV.
B. Notation
In this paper, we use X , M, Z to represent the node poses, submap poses and relative constraints, respectively. Due to multi-session localization, each session consists of several nodes, submaps and constraints. X is the collection of xsi , which i is the index of the node pose and s means the session ID. Analogously, M is composed by msi . It should be emphasized that there are three types of constraints in our system: node-to-submap zm ij ix, node-to-node znijode and submap-to-submap zm ijap. These constraints take the form of relative poses and associated covariance matrice Ωm ij ix, Ωnijode and Ωm ij ap. For example, zm isjixs is the relative transform between the node pose xsi and submap pose msj . The adjacent two node poses are related by the odometry constraint, e.g. zoisdjosm controls xsi and xsj . Speciﬁcally, the pose and constraint is represented by a rotation R ∈ SO(2) and a translation t ∈ R2 because of the ﬂat terrain of indoor environment. Nonetheless, our framework can be easily extended to SE(3).

C. Problem Deﬁnition

Given the poses and relative measurement constraints, the pose graph optimization is formulated as a maximum a posteriori probability (MAP) estimation problem. We then convert the MAP problem into a least square problem with the following cost function:

X ∗, M∗ = argmin J(X , M, Z).

(1)

X ,M

Note that

x

2 Ω

=x

Ω−1x, and J(X , M, Z) is deﬁned by

the following equation:

J (X , M, Z) = x00 Ω0 + m00 Ω0

S−1

+(

xsi msj

s=0 i,j

zmix 2

is j s

Ωmix
is j s

+

xsi xsj

i,j

zodom 2

is j s

Ωodom
is js

(2)

+

xsi xsj

i,j

znode 2

is j s

Ωnode
is j s

+

msi msj

i,j

z ), map 2

is j s

Ωmap
is j s

IV. POSE GRAPH REFINEMENT

In this section, we present the two main components of our system: 1) multi-session localization and 2) pose graph reﬁnement.

A. Multi-session Localization
The methodology of our map management procedure is based on a map update process as depicted in Fig. 3. A robot deployed into a new environment has to execute mapping (in session 0), collect the sensor data(including LiDAR, IMU and wheel encoder) and build the map representation of current environment. The map consists of several occupancy grid submaps, where each submap includes a ﬁxed number LiDAR scans with corresponding poses, i.e. nodes. There are two advantages: 1) the single submap is immune to the global optimization because of local scan-to-submap matching; and 2) it is convenient to update the global map by trimming old submaps and adding new submaps to it. After the mapping stage, the robot performs localization task and creates new submaps from LLO. These submaps are always fresh and continuously recording the newest characteristics of current environment. Once a new submap is created, it is transmitted to the PGR for the subsequent map updating. Apart from LLO, the sensor data are input to GLM. GLM is responsible for calculating the relative measurement constraints between scans and submaps in global map and outputting the constraints to PGR. PGR is the key subsystem of our proposed framework, it receives the fresh submaps and constraints from LLO and GLM, respectively. PGR consists of three modules: submaps trimming, pose graph sparsiﬁcation and pose graph optimization. It maintains the newest submaps by replacing the stale submaps in the old session. Furthermore, in order to keep the sparse characteristic of the pose

graph, the relevant stale submaps, nodes and constraints are removed. The remaining submaps from PGR are transmitted to the global submap database for the subsequent localization task. We call this process "Map Updating".
Fig. 3. Schematic illustration of the map update process. A new map is ﬁrstly built during session 0 of the mapping stage. Given the pre-built map, robot then estimates its pose and updates the map in the following sessions of the localization stage.
Each localization session repeats the aforementioned procedure to estimate the pose of the robot and achieve the updated map.
B. Pose Graph Reﬁnement 1) Submaps Trimming: In the context of lifelong localiza-
tion, new submaps are added to the global map instead of stale submaps whenever the robot is re-entering previously visited terrain. The key idea is to trim the old submaps to limit its number. Most of the existing approaches rely on the environment change detection [10], [11]. They need to ﬁnd out when it is time to update the localization map by comparing the old and latest maps cell-by-cell. To mitigate computation complexity, we adopt the method from [2] that computes the overlapping ratio of the stale submap. In case the ratio is below a deﬁned threshold, the old submaps are not deleted. Otherwise, they are marked as trimmed and deleted in the following pose graph sparsiﬁcation module. The fresh submaps are added to the pose graph regardless of the status of the old submap. The advantage of this method is that we can keep a constant computational time for a robot working in a ﬁxed area.
2) Pose Graph Sparsiﬁcation: A direct way of discarding a trimmed submap is to throw all the constraints and nodes that are connected with the submap. However, such method will lose a lot of information(e.g., the relative measurements between submap and nodes) about the pose graph, and thus resulting in the instability of the graph. Marginalization is a effective way to mitigate this problem. To avoid introducing new edges between all pairs of variables (dense ﬁll-in), which reduces the sparsity of the graph and greatly increase the computational complexity, we adopt the Chow-Liu tree [13] to approximate the individual elimination cliques as sparse tree structures.
Fig. 4 illustrates the sparsiﬁcation process. Given an original pose graph (Fig. 4(a)), a submap with its two nodes

are slated for removal in Fig. 4(b) (blue dotted rectangle). We extract the related submaps and nodes (dots with red dotted circles in Fig. 4(b)) as a local factor graph. After marginalizing out the submap and nodes, the former neighbors form an elimination clique making the graph dense (Fig. 4(c)). By locally approximating the density p(x1, ..., xn) with a probability distribution q(x1, ..., xn) such that each variable is only conditioned upon one of the other variables, we can obtain the sparse local factor graph:

n

p(x1, ..., xn) = p(x1) p(xi|xi−1, ..., x1)

i=2

n

(3)

≈ p(x1) p(xi|xi−1)

i=2

= q(x1, ..., xn),

where x1 is the root variable of the CLT, and xi−1 is the parent of xi. The pairwise conditional distributions are selected such that the Kullback-Leibler divergence (KLD) between the original distribution and the CLT approximation is minimized (Fig. 4(d)). It is given by:

DKL(p||q) =

x

p(x)log

p(x) q(x)

dx.

(4)

Lastly, we merge the approximate clique into the original graph as depicted in Fig. 4(e). The above procedures are described in Algorithm 1. It should be noted that GLM only produces the node-to-submap constraints and inputs them into PGR (see the original pose graph in Fig. 4(a)). However, the node-to-node constraints and submap-to-submap constraints are induced in sparse pose graph (Fig. 4(e)). This is because all nodes and submaps are treated as the same variable type in the elimination clique. By merging the clique into original graph, the variables and pairwise constraints are converted into the corresponding nodes, submaps and their constraints.
After graph sparsiﬁcation, we execute optimization (see the cost function in Eq. (1)) by using the Google Ceres Solver [19].

V. DATASET AND EXPERIMENT
A. Experimental Setup and Dataset
To validate our algorithm, we deploy a three-wheeled cleaning robot in the supermarket as shown in Fig. 5. The algorithm modules including localization, navigation and perception are performed on an industrial computer with Intel i5-4300M CPU and 8G memory. Over a period of a month the robot executed cleaning tasks in the indoor environment with random start position. We choose a supermarket located in Beijing, China as our experimental site because of its highly dynamic ﬂow of people, moving carts, goods, etc. That is a huge challenge for accuracy and stability of any localization algorithm.
Because the test data including scene changes in real world are so valuable for designing more robust localization system, we collected them as dataset and released it in

order to accelerate lifelong SLAM research in the community. The scenes in the dataset include markets, garages and ofﬁces, recored by 2D LiDAR(Sick TiM571) and 3D LiDAR(RoboSense RS-LiDAR-16). The dataset also records other sensor data, including wheel encoder and IMU. For each data sequence, we carefully calibrated the intra-device extrinsics, especially the transform between LiDAR and odometer. We also provided the ground truth poses in a rate of 10 Hz, which are manually veriﬁed by comparing the LiDAR scans with the pre-built consistent map.
B. Algorithm Evaluation
The initial map consists of 550 submaps in session 0, covering an area of over 10000 square meters. These submaps are cached in memory for further localization and cannot be trimmed. To balance the accuracy and computation load, we executed graph optimization every 5 times of sparsiﬁcation and restricted maximum number of iterations in Ceres Solver to 50.
• Environmental Change Based on our map updating method, the robot collects new submaps and trims the old ones during the localization stage. The fresh submaps update the latest representation of current environment whenever the scene changes. Fig. 12 shows the experimental results. (a)(b)(c) are collected from market. The upper left image and upper right image in each column show approximately the same place captured at different time. The lower left and right images show the corresponding map updating results. It should be noted that the appearance of map is not the same as the submaps because we concatenated the submap slices into single occupancy grid map for convenient view. In addition, we test our algorithm in garage scenes and (e)(f)(g) shows the results. Fig. 6 shows the results of map change after running for one month in the market. (a) is pre-built map in mapping stage and (b) is the updated map based on (a).

Algorithm 1: Submap trimming and pose graph sparsiﬁ-

cation

input : Submaps {m0, ..., mk} and pose graph G output: Trimmed submaps {m0, ..., mk} and sparsiﬁed
pose graph G

1 forall mi ∈ {m0, ..., mk} do 2 Get nodes Xintra = {x0, ..., xm} belonging to mi ; 3 Find all constraints Z, nodes X and submaps M
related to mi ; 4 Construct an iSAM graph and add mi, Xintra, X , M
as nodes and Z as factors to the graph ;

// see Eq. (2) and (3)

5 RemoveNodeBasedCLT(mi) ;

6

forall xi in Xintra do

7

RemoveNodeBasedCLT(xi)

8 end

9 delete Xintra, mi from G and merge the remaining

factors from the iSAM graph to G ;

10 end

! "#$%&

! "#$%'

! "#$%(

)*+%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%),+%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%)-+

!"#$%&'()*

%%%).+%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%)!+

+(,*&'()*& -,(#*./0&1(2)./$32. 1(2)./$32.&"*.4**2&+(,*&$2,& !"#$% 1(2)./$32.&"*.4**2&+(,*) 1(2)./$32.&"*.4**2& !"#$%) -/3532&'()*

Fig. 4. An example to illustrate the graph sparsiﬁcation based on the Chow–Liu maximum-mutual-information spanning tree. (a): the original pose graph without submap removal. (b): the central submap m11 is selected to be trimmed along with its nodes: x11 and x12(blue dotted rectangle). The red dotted circles highlight the relevant submaps and nodes that have constraints with blue rectangle. (c): Belief after having marginalized out m11, x11 and x12. The former neighbors of them form an elimination clique making the graph dense. (d): Belief resulting from Chow-Liu tree approximation of the elimination
clique. (e): Merge the elimination clique into original pose graph.

Fig. 5. Our cleaning robot is equipped with a SICK TiM571 2D LiDAR. It is equipped with a magnetic encoders and a HI219M AHRS (with on-board 3-aixs accelerometer, 3-aixs gyroscope and 3-aixs compass) for dead-reckoning. An Intel SR300 RGBD camera is used for perception and obstacle avoidance. Our algorithm is performed on Intel Core i5-4300M 2 cores and 4 threads.

We compare the differences between these two maps as shown in (c). The blue points are the unchanging obstacles in all of time. The light green points are the obstacles that have been removed from the scene, and red points are new added obstacles. We also deﬁne the map change rate (MCR) to evaluate the degree of environment change:

MCR

=

(mr + mg (mr + mg) ∗

) ∗ 0.5 0.5 + mb

,

(5)

where mr, mg, mb is the number of red, green and

blue pixel respectively. The MCR of our map is 51.62%, meaning that more than half of the features have been changed in this scene. This metric can reveal the environment change easily. • Localization Performance Evaluation We execute the robot cleaning task in the market and collect the data sequence separately for comparison of our algorithm with the general SLAM algorithm [2]. For real scene, we cannot obtain the ground-truth poses. Therefore, we design separate metrics to evaluate the correctness and accuracy, respectively. Correctness Rate of Initialization(CRI). Prior to executing a localization task, the robot should receive the initial pose estimation and match the map with collected LiDAR sensor data. A better initialization result can be obtained from a newer map. We deﬁne a index of correct initialization as:

CRI =

N −1 k=0

ck

,

(6)

N

where ck can be deﬁned as:

ck =

1, 0,

if initialization succeed otherwise

(7)

Mileage Rate of Correct Localization(MRCL). By comparing the robot poses output and pre-built map, we can manually verify the correctness of the robot localization trajectory. We use MRCL as the metric. For a sequence

!"################################################################### $"######################################

%"

Fig. 6. Results of map change after one month running in market. (a): The pre-built map. (b): The updated map. (c): Comparison(deﬁne to execute such operation) of (a) and (b). The blue points are obstacles that remain unchanged. The light green points are obstacles which have been removed and red points are newly added obstacles.

3 ! 4 5 6 78 9

3: 33 3! 34 35 36 37 38 39 3 !: !3 !! !4 !5 !6

#$#%&'() 37;!6"

1#-%./-0/$.'+12 87;99"

*+',-%./-0/$.'+12 :;47"

8!"

!"

Fig. 7. Localization testing results with 25 sets data from market. The percentage value on the top left of each algorithm is MRCL and on the bottom right is CRI.

TABLE I AVERAGE MATCHING SCORE COMPARISON

Data Sequence 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25

[2]

0.73 0.72 0.76 0.76 0.72 0.72 0.68 0.67 0.71 0.62 0.52 - 0.68 0.18 - 0.70 0.43 - 0.16 - 0.44 - - 0.42 -

Ours

0.74 0.70 0.78 0.75 0.74 0.74 0.73 0.72 0.72 0.72 0.69 0.68 0.77 0.48 - 0.69 0.59 0.74 0.68 0.68 0.72 0.26 - 0.72 0.58

from t0 to tmax, we deﬁne:

M RCL

=

correct_mileage(t0, tmax) , total_mileage(t0, tmax)

(8)

where correct_mileage() is used to calculate the mileage of correct trajectory and total_mileage() is used to calculate the total mileage. Average Matching Score(AMS). Our method of PGR module is the same with “Global SLAM” module in [2], where building constraints between nodes and submaps relied on a “branch and bound (BNB)” mechanism to work at different grid resolutions. Therefore, we use the BNB score to deﬁne whether a node is correctly matched against a submap. Usually, we set a minimum score(in our experiment, the score is 0.5) to accept a good enough proposal and fed it into PGR. Otherwise, we discard this constraint candidate. Formally, we deﬁne a average score of matching as:

AM S =

M −1 i=0

si

,

(9)

M

where M is the number of matching. si is the i-th BNB score. The results are visualized in Fig. 7, with blue line segments indicating the correct localization trajectory and blue dots indicating whether the initialization is successful or not. Each black dot on the top line

represents the start of a data sequence. The blue line segments start from the blue dots means robot initializes successfully and runs for a while. The length of blue line segments is proportional to a correct mileage. We tested 25 data sequences with three algorithms: original odometry output, method from [2] and ours. The CRI and MRCL from Fig. 7 demonstrate that our method is more robust enough for localization in the challenging environment compared with [2]. However, it should be noted that, in sequence 15 and 23, our method failed to do initialization. This is because the environment is full of pedestrians and the score of scan-matching does not exceed initialization BNB score. The AMS comparison result is listed in Table I. The results show that with longtime map updating, our method achieves higher matching score for robust constraints building based on fresh map. We display the trajectory comparison from 17th data sequence as shown in Fig. 8. The blue line plots the fusion result of wheel encoder and IMU. The green line is from our method and the red line is the result of [2]. It demonstrates that the trajectory of ours is smoother than [2]. The reason is that, with map updating and higher matching score, the valid constraint measurements are much more dense than [2], which only computes constraints based on the stale map.

y[m]

odometry

no map updating[2]

20

with map updating

15

10

5

0

−15

−10

−5

0

5

x[m]

10

15

Fig. 8. Comparison of trajectories from 17th data sequence.

Fig. 10. Lifelong SLAM graph complexity. The number of nodes and submaps remains roughly constant after 15 times of map updating.

Fig. 9. Lifelong SLAM graph complexity. The number of constraints remains roughly constant after 15 times of map updating.

Fig. 11. Computation load changes with 25 times of map updating.

• Computational Complexity Evaluation The size of the pose graph has a direct inﬂuence to the runtime and the memory complexity of the SLAM system and typically grows over time. Therefore, it is desirable to prevent the scale of the graph from growing unbounded. To check the graph scale, we record the essential elements of the pose graph in each map updating. We see in Fig. 10 that the PGR module limit the number of nodes and submaps to less than 22000 nodes and 650 submaps. As shown in Fig. 9, the total number of constraints is under 110000. Fig. 11 depicts the average CPU utilization and memory usage of our SLAM algorithm while robot executed localization task. The computation load is positively associated with the scale of graph. It means that our method will not occupy unlimited resource of the system.
VI. CONCLUSIONS AND FUTURE WORK
To address the problem of environment change in realworld, we present a complete lifelong SLAM framework. The proposed method exploits the multiple localization sessions and map updating strategy, which can be used to track the scene change and achieve an up-to-date map. We also propose a submap-based graph sparsiﬁcation method based

on Chow-Liu maximum-mutual-information spanning tree to balance computational complexity and localization accuracy. We comprehensively validate our method in real supermarket for more than a month. The experiment demonstrates that our method is quite valuable to be deployed in real world. Besides, we release our lifelong SLAM dataset to accelerate robust SLAM research in these scenes.
However, our approach does not at present take into account the unexpected drastic change of the environment. The change may cause localization drift because there are no valid constraint measure between incoming scans and map. In the future, we plan to explore more robust localization algorithm to conquer this problem.
ACKNOWLEDGEMENT
Authors appreciate the great help from our outstanding colleagues, Wenjing Chen, Pengfei Du, Shiwei Wang, Linbing Zen, Bo Wu, Haoxuan Tan, Guolin Li, Aiwei Yin and Youji Zhu.
The video demo is available at https://youtu.be/U7b0zc_ jK74.
REFERENCES
[1] Biber, Peter, and Wolfgang Straßer. "The normal distributions transform: A new approach to laser scan matching." Proceedings 2003

(a)

(b)

(c)

(d)

(e)

(f)

Fig. 12. Examples of environment change and corresponding map updating experiment. The result in (a), (b) and (c) are collected from market. And (d), (e) and (f) are from garage.

IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2003)(Cat. No. 03CH37453). Vol. 3. IEEE, 2003. [2] W. Hess, D. Kohler, H. Rapp, and D. Andor, “Real-time loop closure in 2D LiDAR SLAM,” in Proceedings of the IEEE International Conference on Robotics and Automation (ICRA), 2016, pp. 1271–1278. [3] Censi, Andrea. "An ICP variant using a point-to-line metric." 2008 IEEE International Conference on Robotics and Automation. Ieee, 2008. [4] Olson, Edwin B. "Real-time correlative scan matching." 2009 IEEE International Conference on Robotics and Automation. IEEE, 2009. [5] Cadena C, Carlone L, Carrillo H, Latif Y, Scaramuzza D, Neira J, Reid I and Leonard JJ, “Past, present, and future of simultaneous localization and mapping: Toward the robustperception age),” IEEE Transactions on Robotics 32(6): 1309–1332. [6] Shan, Tixiao, and Brendan Englot. “Lego-loam: Lightweight and ground-optimized lidar odometry and mapping on variable terrain,” 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE, 2018. [7] Mur-Artal, Raul, and Juan D. Tardós. “Orb-slam2: An open-source slam system for monocular, stereo, and rgb-d cameras." IEEE Transactions on Robotics 33.5 (2017): 1255-1262. [8] P. Biber and T. Duckett, “Dynamic maps for long-term operation of mobile service robots,”in RSS, 2005. [9] Biber, Peter, and Tom Duckett. “Experimental analysis of samplebased maps for long-term SLAM,” The International Journal of Robotics Research 28.1 (2009): 20-33. [10] Walcott-Bryant, Aisha, et al. “Dynamic pose graph SLAM: Long-term mapping in low dynamic environments,” 2012 IEEE/RSJ International Conference on Intelligent Robots and Systems. IEEE, 2012. [11] Ding, Wendong, et al. “LiDAR Inertial Odometry Aided Robust LiDAR Localization System in Changing City Scenes,” Proceedings of the IEEE International Conference on Robotics and Automation (ICRA). IEEE (May 2020). [12] Kretzschmar, Henrik, Giorgio Grisetti, and Cyrill Stachniss. “Lifelong map learning for graph-based slam in static environments,” KIKünstliche Intelligenz 24.3 (2010): 199-206. [13] Kretzschmar, Henrik, and Cyrill Stachniss. “Information-theoretic compression of pose graphs for laser-based SLAM,” The International Journal of Robotics Research 31.11 (2012): 1219-1230. [14] Carlevaris-Bianco, Nicholas, Michael Kaess, and Ryan M. Eustice.

“Generic node removal for factor-graph SLAM,” IEEE Transactions on Robotics 30.6 (2014): 1371-1385. [15] Bürki, Mathias, et al. “Map management for efﬁcient long-term visual localization in outdoor environments,” 2018 IEEE Intelligent Vehicles Symposium (IV). IEEE, 2018. [16] Tipaldi, Gian Diego, Daniel Meyer-Delius, and Wolfram Burgard. “Lifelong localization in changing environments,” The International Journal of Robotics Research 32.14 (2013): 1662-1678. [17] Labbé, Mathieu, and François Michaud. “Long-term online multisession graph-based SPLAM with memory management,” Autonomous Robots 42.6 (2018): 1133-1150. [18] Egger, Philipp, et al. “Posemap: Lifelong, multi-environment 3d lidar localization,” 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS). IEEE, 2018. [19] S. Agarwal, K. Mierle, and Others, “Ceres solver,” http://ceressolver.org.

