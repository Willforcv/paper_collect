A Systematic Literature Review on Federated Machine Learning: From A Software Engineering Perspective

arXiv:2007.11354v9 [cs.SE] 28 May 2021

SIN KIT LO, Data61, CSIRO and University of New South Wales, Australia QINGHUA LU, Data61, CSIRO and University of New South Wales, Australia CHEN WANG, Data61, CSIRO, Australia HYE-YOUNG PAIK, University of New South Wales, Australia LIMING ZHU, Data61, CSIRO and University of New South Wales, Australia
Federated learning is an emerging machine learning paradigm where clients train models locally and formulate a global model based on the local model updates. To identify the state-of-the-art in federated learning and explore how to develop federated learning systems, we perform a systematic literature review from a software engineering perspective, based on 231 primary studies. Our data synthesis covers the lifecycle of federated learning system development that includes background understanding, requirement analysis, architecture design, implementation, and evaluation. We highlight and summarise the findings from the results, and identify future trends to encourage researchers to advance their current work.
CCS Concepts: • Computing methodologies → Artificial intelligence; Machine learning; • Software and its engineering; • Security and privacy;
Additional Key Words and Phrases: federated learning, systematic literature review, software architecture, software engineering, machine learning, distributed learning, edge learning, privacy, communication
ACM Reference Format: Sin Kit Lo, Qinghua Lu, Chen Wang, Hye-young Paik, and Liming Zhu. 2020. A Systematic Literature Review on Federated Machine Learning: From A Software Engineering Perspective. J. ACM 37, 4, Article 111 (August 2020), 38 pages. https://doi.org/10.1145/1122445.1122456

1 INTRODUCTION
Machine learning is adopted broadly in many areas, and data plays a critical role in machine learning systems due to its impact on the model performance. Although the widely deployed remote devices (e.g., mobile/IoT devices) generate massive amounts of data, data hungriness is still a challenge because of the increasing concern in data privacy (e.g., General Data Protection Regulation - GDPR [3])
To effectively address this challenge, federated learning was proposed by Google in 2016 [113]. In federated learning, client devices perform model training locally and generate a global model collaboratively. The data is stored locally and never transferred to the central server or other clients [39, 73]. Instead, only model updates are communicated for formulating the global model.

Authors’ addresses: Sin Kit Lo, Kit.Lo@data61.csiro.au, Data61, CSIRO and University of New South Wales, Australia; Qinghua Lu, qinghua.lu@data61.csiro.au, Data61, CSIRO and University of New South Wales, Australia; Chen Wang, Chen.Wang@data61.csiro.au, Data61, CSIRO, Australia; Hye-young Paik, h.paik@unsw.edu.au, University of New South Wales, Australia; Liming Zhu, Liming.Zhu@data61.csiro.au, Data61, CSIRO and University of New South Wales, Australia.

Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org.
© 2020 Association for Computing Machinery. 0004-5411/2020/8-ART111 $15.00 https://doi.org/10.1145/1122445.1122456

111

J. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2020.

111:2

Lo, et al.

The growing interest in federated learning has increased the number of research projects and publications in the last four years. Although there are surveys conducted on this topic [73, 93, 95], there is still no systematic literature review on federated learning. It motivates us to perform a systematic literature review on federated learning to understand the state-of-the-art. Furthermore, client devices in federated learning systems form a large-scale distributed system. It calls for software engineering considerations apart from the core machine learning knowledge [163]. Thus, we explore how to develop federated learning systems by conducting a systematic literature review to provide a holistic and comprehensive view of the state-of-the-art federated learning research, especially from a software engineering perspective.
We perform a systematic literature review following Kitchenham’s standard guideline [81]. The objectives are to: (1) provide an overview of the research activities and diverse research topics in federated learning system development; (2) help practitioners understand challenges and approaches to develop a federated learning system. The contributions of this paper are as follow:
• We present a comprehensive qualitative and quantitative synthesis reflecting the state-of-theart in federated learning with data extracted from 231 primary studies. Our data synthesis investigates different stages of federated learning system development.
• We provide all the empirical findings and identify future trends in federated learning research.
The remainder of the paper is organised as follows: Section 2 introduces the methodology. Section 3 presents the results and highlights the findings. Section 4 identifies future trends, followed by threats to validity in Section 5. Section 6 discusses related work. Section 7 concludes the paper.
2 METHODOLOGY
Based on Kitchenham’s guideline [81], we developed the following protocol.

Fig. 1. Research questions mapping with Software Development Life Cycle (SDLC)
2.1 Research Questions To provide a systematic literature review from the software engineering perspective, we view federated learning as a software system and study federated learning systems from the software development standpoint. As shown in Fig 1, we adopt the software development practices of machine learning systems in [163] to describe the software development lifecycle (SDLC) for federated learning. In this section, we explain how each research question (RQ) is derived.
J. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2020.

A Systematic Literature Review on Federated Machine Learning: From A Software Engineering Perspective

111:3

2.1.1 Background Understanding: To develop a federated learning system, we need to first know what federated learning is and when to adopt federated learning instead of centralised learning. Thus, we derive RQ 1 (What is federated learning?) and RQ 1.1 (Why is federated learning adopted?). After learning the background and adoption objectives of federated learning, we intend to identify the research efforts and the experts in this field through RQ 2.1 (How many research activities have been conducted on federated learning?) and RQ 2.2 (Who is leading the research in federated learning?). Lastly, we derive RQ 3.2 (What are the phases of the machine learning pipeline covered by the research activities?) to examine the focused machine learning pipeline stages in the existing studies and understand the maturity of the area.
2.1.2 Requirement Analysis: After the background understanding stage, the requirements of federated learning systems are analysed. We focus on the non-functional requirements since functional requirements are application-specific. We derive RQ 2 (What challenges of federated learning are being addressed?) to identify the architectural drivers (i.e. non-functional requirements) of federated learning systems. RQ 1.2 (What are the applications of federated learning?), RQ 1.3 (What data does the federated learning applications deal with?) and RQ 1.4 (What is the client data distribution of the federated learning applications?) are designed to help researchers and practitioners assess the suitability of federated learning for their systems, which is within the scope of the requirement analysis.
2.1.3 Architecture Design: After the requirement analysis, researchers and practitioners need to understand how to design the architecture. For this, we consider the approaches against each requirement. Hence, we derive RQ 3 (How are the federated learning challenges being addressed?) and RQ 3.1 (What are the possible components of federated learning systems?). These 2 RQs aim (1) to identify the possible approaches that address the challenges during the federated learning system development, and (2) to extract the software components for federated learning architecture design to fulfill the non-functional requirements (i.e. challenges).
2.1.4 Implementation and Evaluation: After the architecture design stage, once the system is implemented, the federated learning systems including the built models need to be evaluated. Thus, we derive RQ 4 (How are the approaches evaluated?) and RQ 4.1 (What are the evaluation metrics used to evaluate the approaches?) to identify the methods and metrics for the evaluation of federated learning systems.

2.2 Sources Selection and Strategy
We searched through the following search engines and databases: (1) ACM Digital Library, (2) IEEE Xplorer, (3) ScienceDirect (4) Springer Link, (5) ArXiv, and (6) Google scholar. The search time frame is set between 2016.01.01 and 2020.01.31. We screened and selected the papers from the initial search according to the preset inclusion and exclusion criteria elaborated in Section 2.2.2.
We then conducted forward and backward snowballing processes to search for any related papers that were left out from the initial search. The paper selection process consists of 2 phases: (1) The papers were first selected by two researchers through title and abstract screening independently, based on the inclusion and exclusion criteria. Then, the two researchers cross-checked the results and resolved any disagreement on the decisions. (2) The papers selected in the first phase were then assessed through full-text screening. The two researchers again cross-checked the selection results and resolved any disagreement on the selection decisions. Should any disagreement have occurred in either the first or the second phase, a third researcher (meta-reviewer) was consulted to finalise the decision. Fig. 2 shows the paper search and selection process.

J. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2020.

111:4

Lo, et al.

The initial search found 1074 papers, with 76 from ACM Digital Library, 320 from IEEE Xplorer, 5 from ScienceDirect, 85 from Springer Link, 256 from ArXiv, and 332 from Google scholar. After the paper screening, exclusion, and duplicates removal, we ended up with 225 papers. From there, we conducted the snowballing process and found 6 more papers. The final paper number for this review is 231. The number of papers per source are presented in Table 1.

Table 1. Number of selected publications per source

Sources ACM IEEE Springer ScienceDirect ArXiv Google Scholar Total

Paper count 22 74

17

4

106

8

231

Fig. 2. Paper search and selection process map

2.2.1 Search String Definition. We used “Federated Learning” as the key term and included synonyms and abbreviations as supplementary terms to increase the search results. We designed the search strings for each primary source to check the title, abstract, and keywords. After completing the first draft of search strings, we examined the results of each search string against each database to check the effectiveness of the search strings. The finalised search terms are shown in Table 2. The search strings and the respective paper quantities of the initial search for each primary source are shown in Table 3, 4, 5, 6, 8, and 7.
Table 2. Key and supplementary search terms

Key Term Federated Learning

Supplementary Terms
Federated Machine Learning, Federated ML, Federated Artificial Intelligence, Federated AI, Federated Intelligence, Federated Training

Table 3. Search strings and quantity of ACM Digital Library

Search string
Result quantity Selected papers

All: "federated learning"] OR [All: ,] OR [All: "federated machine learning"] OR [All: "federated ml "] OR [All: ,] OR [All: "federated intelligence"] OR [All: ,] OR [All: "federated training"] OR [All: ,] OR [All: "federated artificial intelligence"] OR [All: ,] OR [All: "federated ai"] AND [Publication Date: (01/01/2016 TO 01/31/2020)]
76
22

J. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2020.

A Systematic Literature Review on Federated Machine Learning: From A Software Engineering Perspective

111:5

Table 4. Search strings and quantity of IEEE Xplorer

Search string
Result quantity Selected papers

("Document Title":"federated learning" OR "federated training" OR "federated intelligence" OR "federated machine learning" OR "federated ML" OR "federated artificial intelligence" OR "federated AI") OR ("Author Keywords":"federated learning" OR "federated training" OR "federated intelligence" OR "federated machine learning" "federated ML" OR "federated artificial intelligence" OR "federated AI")
320
71

Table 5. Search strings and quantity of ScienceDirect

Search string
Result quantity Selected papers

"federated learning" OR "federated intelligence" OR "federated training" OR "federated machine learning" OR "federated ML" OR "federated artificial intelligence" OR "federated AI"
5
4

Table 6. Search strings and quantity of Springer Link

Search string
Result quantity Selected papers

"federated learning" OR "federated intelligence" OR "federated training" OR "federated machine learning" OR "federated ML" OR "federated artificial intelligence" OR "federated AI"
85
17

Table 7. Search strings and quantity of ArXiv

Search string
Result quantity Remark
Selected papers

order: -announced_date_first; size: 200; date_range: from 2016-01-01 to 2020-01-31 include_cross _list:True; terms: AND title=“federated learning” OR “federated intelligence” OR “federated training” OR “federated machine learning” OR “federated ML” OR “federated artificial intelligence” OR “federated AI”; OR abstract=“federated learning” OR “federated intelligence” OR “federated training” OR “federated machine learning” OR “federated ML” OR “federated artificial intelligence” OR “federated AI”
256 Search title and abstract only (ArXiv does not provide keyword search option)
103

2.2.2 Inclusion and Exclusion Criteria. The inclusion and exclusion criteria are formulated to effectively select relevant papers. After completing the first draft of the criteria, we conducted a pilot study on 20 randomly selected papers. Then, the two independent researchers cross-validated the papers selected by the other researcher and refined the criteria. The finalised inclusion criteria are as follow:
• Both long and short papers that have elaborated on the component interactions of the federated learning system: We specifically focus on the research works that provide comprehensive explanations on the federated learning components functionalities and their mutual interactions.
• Survey, review, and SLR papers: We included all the surveys and review papers to identify the open problems and future research trends in an objective manner. However, we excluded them from the stages for answering research questions.
J. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2020.

111:6

Lo, et al.

Table 8. Search strings and quantity of Google scholar

Search string
Result quantity Remark
Selected papers

"federated learning" OR "federated intelligence" OR "federated training" OR "federated machine learning" OR "federated ML" OR "federated artificial intelligence" OR "federated AI"
332 Search title only (Google scholar does not provide abstract & keyword search option)
8

• We included ArXiv and Google scholar’s papers cited by the peer-reviewed papers published in the primary sources.
The finalised exclusion criteria are as follow:
• Papers that elaborate only low-level communication algorithms: The low-level communication algorithms or protocols between hardware devices are not the focus of this work.
• Papers that focus only on pure gradient optimisation. We excluded the papers that purely focus on the gradient and algorithm optimisation research. Our work focuses on the multi-tier processes and interactions of the federated learning software components.
• Papers that are not in English. • Conference version of a study that has an extended journal version. • PhD dissertations, tutorials, editorials and magazines.
2.2.3 Quality Assessment. A quality assessment scheme was developed to evaluate the quality of the papers. There are 4 quality criteria (QC) used to rate the papers. We used numerical scores ranging from 1.00 (lowest) to 5.00 (highest) to rate each paper. The average scores are calculated for each QC and the total score of all 4 QCs are obtained. We included papers that score greater than 1.00 to avoid missing out on studies that are insightful while maintaining the quality of the search pool. The QCs are as follow:
• QC1: The citation rate. We identified this by checking the number of citations received by each paper according to Google scholar.
• QC2: The methodology contribution. We identified the methodology contribution of the paper by asking 2 questions: (1) Is this paper highly relevant to the research? (2) Can we find a clear methodology that addresses its main research questions and goals?
• QC3: The sufficient presentation of the findings. Are there any solid findings/results and clear-cut outcomes? Each paper is evaluated based on the availability of results and the quality of findings.
• QC4: The future work discussions. We assessed each paper based on the availability of discussions on future work.
2.2.4 Data Extraction and Synthesis. We downloaded all the selected papers and recorded all the essential information, including the title, source, year, paper type, venue, authors, affiliation, the number of citations of the paper, the score from all QCs, the answers for each RQ, and the research classification (refer to Appendix A.11). The following steps were followed to prevent any data extraction bias:
• The two independent researchers conducted the data extraction of all the papers and cross checked the classification and discussed any dispute or inconsistencies in the extracted data.
1Data extraction sheet, https://drive.google.com/file/d/10yYG8W1FW0qVQOru_kMyS86owuKnZPnz/view?usp=sharing
J. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2020.

A Systematic Literature Review on Federated Machine Learning: From A Software Engineering Perspective

111:7

• For any unresolved dispute on the extracted data, the first two authors tried to reach an agreement. When an agreement was not met, the meta reviewer reviewed the paper and finalised the decision together.
• All the data was recorded in the Google sheet for analysis and synthesis processes.
3 RESULTS In this section, the extracted results of each research question are summarised and analysed.

Fig. 3. RQ 1: What is federated learning?

Table 9. Characteristics of federated learning

Category

Characteristic

Paper count

Training a model on multiple clients

200

Training settings (82%) Only sending model updates to the central server

133

Producing a global model on the central server

63

Data distribution (11%)

Decentralised data storage Data generated locally

40 17

Orchestration (3%)

Training organised by a central server

13

Cross-device

11

Client types (3%)

Cross-silo

1

Both

3

Data partitioning (<1%)

Horizontal federated learning Vertical federated learning

1 1

3.1 RQ 1: What is federated learning?
The first research question (RQ 1) is "What is federated learning?". To answer RQ 1, the definition of federated learning reported by each study is recorded. This question helps the audience to understand: (1) what federated learning is, and (2) the perceptions of researchers on federated learning. Fig. 3 is a word cloud that shows the frequency of the words that appear in the original definition of federated learning in each study. The most frequently appeared words include: distribute, local, device, share, client, update, privacy, aggregate, edge, etc. To answer RQ1 more accurately, we use these five categories to classify the definitions of federation learning: (1) training settings, (2) data distribution, (3) orchestration, (4) client types, and (5) data partitioning, as understood by the researchers, as shown in Table 9.
First, in the training settings, building a decentralised or distributed learning process over multiple clients is what most researchers conceived as federated learning. This can be observed as the most
J. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2020.

111:8

Lo, et al.

frequently mentioned keyword in RQ1 is “training a model on multiple clients”. Other frequently mentioned keywords that describe the training settings are “distributed”, “collaborative”, and “multiple parties/clients”. “Only sending the model updates to the central server” and “producing a global model on the central server” are the other two characteristics that describe how a federated learning system performs model training in a distributed manner. This also shows how researchers differentiate federated learning from conventional machine learning and distributed machine learning.
Secondly, federated learning can be explained in terms of the data distributions. The keywords mentioned in the studies are “data generated locally” and “data stored decentralised”. Data is collected and stored by client devices in different geographical locations. Hence, it exhibits non-IID (non-Identically & Independently Distributed) and unbalanced data properties [73, 113]. Furthermore, the data is decentralised and is not shared with other clients to preserve data privacy. We will discuss more on the client data distribution in Section 3.4.
Thirdly, researchers observe federated learning from the training process orchestration standpoint. In conventional federated learning, a central server orchestrates the training processes. The tasks consist of initialisation of a global model, distribution of the global models to participating client devices, collection of trained local models, and the aggregation of the collected local models to update the global model. Intuitively, researchers consider the usage of a single central server as a possible single-point-of-failure [110, 143]. Hence, decentralised approaches for the exchange of model updates are studied and the adoption of blockchains for decentralised data governance is introduced [110, 143].
Fourthly, we observe two types of federated learning in terms of client types which are crossdevice and cross-silo. Cross-device federated learning deals with a massive number of smart devices, creating a large-scale distributed network to collaboratively train a model for the same applications [73]. Some examples of the applications are mobile device keyboard word suggestions and human activity recognition. The setting are extended to cross-silo applications where data sharing between organisations is prohibited. For instance, data of a hospital is prohibited from exposure to other hospitals due to data security regulations. To enable machine learning under this environment, cross-silo federated learning conducts local model training using the data in each hospital (silo) [73, 160].
Lastly, we found 3 data partitioning variations: horizontal, vertical, and federated transfer learning. Horizontal federated learning, or sample-based federated learning, is used when the datasets share the same feature space but different sample ID space [103, 183]. Inversely, vertical federated learning, also known as feature-based federated learning, is applied to the cases where two or more datasets share the same sample ID space but different feature space. Federated transfer learning considers the data partitioning where two datasets only overlap partially in the sample space or the feature space. It aims to develop models that are applicable to both datasets [183].
We summarised the findings as below. We connected each keyword and grouped them under the same definition. Finally, we arranged the definitions according to the frequency of the words that appeared.

3.2 RQ 1.1: Why is federated learning adopted?
The motivation of RQ 1.1 is to understand the advantages of federated learning. We classify the answers based on the non-functional requirements of federated learning adoption (illustrated in Fig. 4). Data privacy and communication efficiency are the two main motivations to adopt federated learning. Data privacy is preserved in federated learning as no raw local data moves out of the device [20, 135]. Also, federated learning achieves higher communication efficiency by exchanging

J. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2020.

A Systematic Literature Review on Federated Machine Learning: From A Software Engineering Perspective

111:9

Findings of RQ 1: What is federated learning (FL)?
Federated learning is a type of distributed machine learning to preserve data privacy. Federated learning systems rely on a central server to coordinate the model training process on multiple, distributed client devices where the data are stored. The model training is performed locally on the client devices, without moving the data out of the client devices. Federated learning can also be performed in a decentralised manner.
Variations in federated learning: (1) centralised/decentralised federated learning, (2) cross-silo/device federated learning, (3) horizontal/vertical/transfer federated learning.
With regard to the software development lifecycle, this question contributes to the background understanding phase where we provide the definition of the fundamental settings and different variations of federated learning as reported by researchers and practitioners.

Fig. 4. RQ 1.1: Why federated learning is adopted?
only model parameters or gradients [73, 113, 183]. High data privacy and communication efficiency also promote scalability. Hence, more clients are motivated to join the training process [73, 113, 183].
Statistical heterogeneity is defined as the data distribution with data volume and class distribution variance among devices (i.e. Non-IID). Essentially, the data are massively distributed across client devices, each only contains small amount of data [119, 138, 198], with unbalanced data classes [119] that are not representative of the overall data distribution [64]. When local models are trained independently on these devices, these models tend to be over-fitted to their local data [97, 138, 198]. Hence, federated learning is adopted to collaboratively trains the local models to form a generalised global model. System heterogeneity is defined as the property of devices having heterogeneous resources (e.g, computation, communication, storage, and energy). Federated learning can tackle this issue by enabling local model training and only communicates the model updates, which reduce the bandwidth footprint and energy consumption [7, 36, 97, 119, 136, 154, 166].
Another motivation is high computation efficiency. With a large number of participating clients and the increasing computation capability of clients, federated learning can have high model performance [12, 38, 113, 150, 205] and computation efficiency [11, 62, 198]. Data storage efficiency is ensured by independent on-client training using locally generated data [22, 113, 146, 194, 208].
J. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2020.

111:10

Lo, et al.

Findings of RQ 1.1: Why is federated learning adopted?
Motivation for adoption: Data privacy and communication efficiency are the two main motivations. Only a small number of studies adopt federated learning because of model performance. With a large number of participating clients, federated learning is expected to achieve high model performance. However, the approach is still immature when dealing with non-IID and unbalanced data distribution.
With regard to the software development lifecycle, this question contributes to the background understanding phase where we identify the objectives of federated learning adoption.

Table 10. Data Types and Applications Distribution

Data Types (RQ 1.3)

Applications (RQ 1.2)

Count

Graph data (5%)
Image data (49%)
Sequential data (4%)
Structured data (21%)

Generalized Pareto Distribution parameter estimation

1

Incumbent signal detection model

1

Linear model fitting

1

Network pattern recognition

8

Computation resource management

1

Waveform classification

1

Autonomous driving

5

Healthcare (Bladder contouring, whole-brain segmentation)

2

Clothes type recognition

14

Facial recognition

2

Handwritten character/digit recognition

109

Human action prediction

2

Image processing (classification/defect detection)

4

Location prediction

1

Phenotyping system

1

Content recommendation

2

Game AI model

2

Network pattern recognition

1

Content recommendation

1

Robot system navigation

1

Search rank system

6

Stackelberg competition model

2

Air quality prediction

2

Healthcare

25

Credit card fraud detection

3

Bankruptcy prediction

5

Content recommendation (e-commerce)

1

Energy consumption prediction

1

Economic prediction (financial/house price/income/loan/market)

11

Human action prediction

4

Multi-site semiconductor data fusion

1

Particle collision detection

1

Industrial production recommendation

1

Publication dataset binary classification

1

Quality of Experience (QoE) prediction

1

Search rank system

1

Sentiment analysis

1

System anomaly detection

1

Song publishment year prediction

1

J. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2020.

A Systematic Literature Review on Federated Machine Learning: From A Software Engineering Perspective

Text data (14%)
Time-series data (7%)

Customer satisfaction prediction

1

Keyboard suggestion (search/word/emoji)

21

Movie rating prediction

4

Out-of-Vocabulary word learning

1

Suicidal ideation detection

1

Product review prediction

1

Resource management model

1

Sentiment analysis

5

Spam detection

2

Speech recognition

1

Text-to-Action decision model

1

Content recommendation

1

Wine quality prediction

1

Air quality prediction

1

Automobile MPG prediction

1

Healthcare (gestational weight gain / heart rate prediction)

2

Energy prediction (consumption/demand/generation)

3

Human action prediction

8

Location prediction

1

Network anomaly detection

1

Resource management model

2

Superconductors critical temperature prediction

1

Vehicle type prediction

1

111:11

3.3 RQ 1.2 What are the applications of federated learning? & RQ 1.3: What data does the federated learning applications deal with?
We study the federated learning applications and the types of data used in those applications through RQ 1.2 and RQ 1.3. The data types and applications are listed in Table 10. The most widely used data types are image data, structured data, and text data, while the most popular application is image classification. In fact, MNIST2 is the most frequently used dataset. More studies are needed to deal with IoT time-series data. Both graph data and sequential data are not popularly used in federated learning due to their data characteristics. We observed that the federated learning is widely adopted in applications that infer personal data, such as images, personal medical or financial data, and text recorded by personal mobile devices.
Findings of RQ 1.2: What are the applications of federated learning? & RQ 1.3: What data does the federated learning applications deal with? Applications and data: Federated learning is widely adopted in applications that deal with image data, structured data, and text data. Both graph data and sequential data are not popularly used due to their data characteristics (e.g., non-linear data structure). Also, there is only a few production-level applications. Most applications are still proof-of-concept prototypes or simulations. With regard to the software development lifecycle, this question contributes to the requirement analysis phase where we identify the different applications and data types that have applied federated learning as a reference for researchers and practitioners.

3.4 RQ 1.4: What is the client data distribution of the federated learning applications? Table 11 shows the client data distribution types found in the studies. 24% of the studies have adopted non-IID data or have addressed the non-IID issue in their work. 23% of the studies have adopted IID data. 13% of the studies have compared the two types of client data distributions (Both), whereas 40% of the studies have not specified which data distribution they have adopted (N/A). These studies ignored the effect of data distribution on the federated model performance. In the
2The MNIST database of handwritten digits, http://yann.lecun.com/exdb/mnist/
J. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2020.

111:12

Lo, et al.

simulated non-IID data distribution settings, researchers mainly split the dataset by class and store each class into different client devices (e.g., [31, 66, 67, 153, 202]), or by sorting the data accordingly before distributing them to each client device [114]. Furthermore, the data volume is uneven for each client device [67, 80]. For use case evaluations, the non-IID data are generated or collected by local devices, such as [42, 45, 57, 84, 134]. For IID data distribution settings, the data are randomised and distributed evenly to each client device (e.g., [13, 72, 114, 153, 202]).

Findings of RQ 1.4: What is the client data distribution of the federated learning applications?
Client data distribution: The client data distribution influences the federated learning model performance. Model aggregation should consider that the distribution of the dataset on each client is different. Many studies are conducted on Non-IID issues, particularly on the FedAvg algorithm extensions for model aggregation.
With regard to the software development lifecycle, this question contributes to the requirement analysis phase where we identify the characteristics of the different types of data distribution that affect the federated learning model performance.

Table 11. Client data distribution types of federated learning applications

Data distribution types Non-IID IID Both N/A

Percentages

24% 23% 13% 40%

3.5 RQ 2: What challenges of federated learning are being addressed? & RQ 2.1: How
many research activities have been conducted on federated learning?
The motivation of RQ 2 is to identify the challenges of federated learning that are addressed by the studies. As shown in Fig. 5, we group the answers into categories based on ISO/IEC 25010 System and Software Quality model [2] and ISO/IEC 25012 Data Quality model [1]. We can observe that the communication efficiency of federated learning received the most attentions from researchers, followed by statistical heterogeneity and system heterogeneity.
To explore the research interests evolved from 2016 to 2019, we cross-examined the results for RQ 2 and RQ 2.1 as illustrated in Fig. 6. Note that we included the results from 2016-2019 as we only searched studies up to 31.01.2020 and the trend of one month does not represent the trend of the entire year. We can see that the number of studies on communication efficiency, statistical heterogeneity, system heterogeneity, data security, and client device security surged drastically in 2019 compared to the years before.

Fig. 5. Challenges of federated learning J. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2020.

A Systematic Literature Review on Federated Machine Learning: From A Software Engineering Perspective

111:13

Although transferring model updates instead of raw data can reduce communication costs, federated learning systems still perform multiple update iterations to reach convergence. Therefore, ways to reduce communication rounds are studied (e.g., [41, 114, 148]). Furthermore, cross-device federated learning needs to accommodate a large number of client devices. Hence, some clients may drop out due to bandwidth limitation [40, 175]. These dropouts could negatively impact the outcome of federated learning systems in two ways: (i) reduce the amount of data available for training [40], (ii) increase the overall training time [111, 147]. The mechanism in [104] addresses the dropout problem by abandoning the global model aggregated from a low number of local models.
Federated learning is effective in dealing with statistical and system heterogeneity issues through the aggregation of local models trained locally on client devices [36, 97]. However, the approach is still immature as open questions exist in handling the non-IID while maintaining the model performance [36, 66, 158, 161, 190].
The interests in data security (e.g., [19, 49]) and client device security (e.g., [35, 48, 171]) are also high. The data security in federated learning is the degree to which a system ensures data are accessible only by an authorised party [1]. While federated learning systems restrict raw data from leaving local devices, it is still possible to extract private information through back-tracing the gradients. The studies under this category mostly express their concerns about the possibility of information leakage from the local model gradient updates. Client device security can be expressed as the degree of security against dishonest and malicious client devices [73]. The existence of malicious devices in the training process could poison the overall model performance by disrupting the training process or providing false updates to the central server. Furthermore, the intentional or unintentional misbehavior of client devices could reduce system reliability.
Client motivatability is discussed as an aspect to be explored (e.g., [79, 80, 196]) since model performance relies greatly on the number of participating clients. More participating clients means more data and computation resources are contributed to the model training process.
System reliability concerns are mostly on the adversarial or byzantine attacks that target the central server, hence exposes the single-point-of-failure (e.g., [63, 87, 110]). The system performance of federated learning systems is mentioned in some studies (e.g. [34, 106, 174]), which includes the considerations on computation efficiency, energy usage efficiency, and storage efficiency. In resource-restricted environments, the efficient resource management of federated learning systems is more crucial to system performance.
To improve system auditability, auditing mechanisms (e.g., [8, 72, 170]) are used to track the client devices’ behavior, local model performance, and system runtime performance. Scalability is also mentioned as a limitation in federated learning (e.g., [135, 142, 143, 174]) and lastly, the model performance limitation is investigated (e.g., [64, 69, 123]). The model performance of federated learning systems is highly dependent on the number of participants and the data volume of each participating client in the training process. Moreover, there is model performance limitation due to the non-IID data.

Findings of RQ 2: What challenges of federated learning are being addressed?
Motivation vs. challenges: Most of the known motivations of federated learning also appear to be the most studied federated learning limitations, including communication efficiency, system and statistical heterogeneity, model performance, and scalability. This reflects that federated learning is still under-explored.
With regard to the software development lifecycle, this question contributes to the requirement analysis phase where we identify the various requirements of a federated learning system to be considered during the development.

To answer RQ 2.1, we classify the papers according to the research classification criteria proposed by Wieringa [172], which includes: (1) evaluation research, (2) philosophical papers, (3) proposal
J. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2020.

111:14

Lo, et al.

Fig. 6. Research Area Trend

of solution, and (4) validation research. We use this classification to distinguish the focus of each research activity. Evaluation research is the investigation of a problem in software engineering practice. In general, the research results in new knowledge of causal relationships among phenomena, or in new knowledge of logical relationships among propositions. The causal properties are studied through case or field studies, field experiments and surveys. Philosophical papers propose a new way of looking at things, for instance, a new conceptual framework. Proposal of solution papers propose solution techniques and argue for its relevance, but without a full-blown validation. Lastly, validation research investigates the properties of a proposed solution that has not yet been implemented in practice. The investigation uses a thorough, methodologically sound research setup (e.g., experiments, simulations).
The research classification results are presented in Table 12. By far the most common type of research is validation research, while the other types of are far less frequent. In particular, there are few philosophical papers that propose a new conceptual framework for federated learning.
Table 12. The research classification of the selected paper

Research Classification
Paper count

Evaluation research 13

Philosophical paper 12

Proposal of solution 25

Validation research
183

Findings of RQ 2.1: How many research activities have been conducted on federated learning? Research activities: The number of studies that explored communication efficiency, statistical and system heterogeneity, data security, and client device security surged drastically in 2019 compared to the years before. The most conducted research activities are validation research, followed by proposal of solution, evaluation research, and philosophical papers. With regard to the software development lifecycle, this question contributes to the background understanding phase where we identify the types of research activities on federated learning.
3.6 RQ 2.2: Who is leading the research in federated learning? The motivation of RQ 2.2 is to understand the research impact in the federated learning community. We also intend to help researchers identify the state-of-the-art research in federated learning by
J. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2020.

A Systematic Literature Review on Federated Machine Learning: From A Software Engineering Perspective Table 13. Research Impact Analysis

111:15

Top 10 affiliations by number of papers

Top 10 affiliations by number of citations

Rank 1 2 3 3 5 5 7 7 9 9

Affiliations Google IBM WeBank Nanyang Technological University Tsinghua University Carnegie Mellon University (CMU) Beijing University of Posts and Telecommunications Kyung Hee University Chinese Academy of Sciences Imperial College London

Paper count 21 11 8 8 6 6 5 5 4 4

Rank 1 2 3 4 5 6 7 8 9 10

Affiliations Google Stanford University ETH Zurich IBM Cornell University Carnegie Mellon University (CMU) ARM Tianjin University University of Oulu WeBank

No. of citations 2269 217 130 122 101 98 82 76 73 66

selecting the top affiliations. As shown in table 13, we listed the top 10 affiliations by the number of papers published and the number of citations. Google, IBM, CMU, and WeBank appear in both the top-10 lists. From this table, we can identify the research institutions that made the most effort on federated learning and those that made the most impact on the research domain in terms of citations.
Findings of RQ 2.2: Who is leading the research in federated learning? Affiliations: Google, IBM, CMU, and WeBank appear in the top 10 affiliations list both by the number of papers and by the number of citations, which reflect that they made the most efforts on federated learning and also the most impact on the research domain. With regard to the software development lifecycle, this question contributes to the background understanding phase where we provide the list of leading affiliations to help researchers and practitioners identify the state-of-the-art of federated learning.

3.7 RQ 3: How are the federated learning challenges being addressed?
After looking at the challenges, we studied the approaches proposed by the researchers to address these challenges. Fig. 7 shows the existing approaches: model aggregation (63), training management (24), incentive mechanisms (18), privacy-preserving mechanisms (16), decentralised aggregation (15), security management (12), resource management (13), communication coordination (8), data augmentation (7), data provenance (7), model compression (8), feature fusion/selection (4), auditing mechanisms (4), evaluation (4), and anomaly detection (3). We also mapped these approaches to the challenges of federated learning in Table 14. Notice that we did not include every challenge mentioned in the collected studies but only those that have a proposed solution.
As shown in Fig. 7, model aggregation mechanisms are the most proposed solution by the studies. From Table 14, we can see that model aggregation mechanisms are applied to address communication efficiency, statistical heterogeneity, system heterogeneity, client device security, data security, system performance, scalability, model performance, system auditability, and system reliability issues.
Researchers have proposed various kinds of aggregation methods, including selective aggregation [76, 190], aggregation scheduling [153, 180], asynchronous aggregation [29, 174], temporally weighted aggregation [121], controlled averaging algorithms [77], iterative round reduction [114, 148], and shuffled model aggregation [50]. These approaches aim to: (1) reduce communication cost and latency for better communication efficiency and scalability; (2) manage the device computation and energy resources to solve system heterogeneity and system performance issues, and (3) select high quality models for aggregation based on the model performance. Some
J. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2020.

111:16

Lo, et al.

researchers have proposed secure aggregation to solve data security and client device security issues [17, 18, 20].
Decentralised aggregation is a type of model aggregations which removes the central server from the federated learning systems and is mainly adopted to solve system reliability limitations. The decentralised aggregation can be realised through a peer-to-peer system [138, 144], one-hop neighbours collective learning [85], and Online Push-Sum (OPS) methods [59].
Training management is the second most proposed approach in the studies. It is used to address statistical heterogeneity, system heterogeneity, communication efficiency, client motivatability, and client device security issues. To deal with the statistical heterogeneity issue, researchers have proposed various training methods, such as the clustering of training data [23, 141], multi-stage training and fine-tuning of models [71], brokered learning [47], distributed multitask learning [36, 149], and edge computing [101]. The objectives are to increase the training data and reduce data skewness effect while maintaining a distributed manner. Furthermore, to address system heterogeneity issues, some methods balance the tasks and resources of the client nodes for the training process [39, 53, 89].
Another frequently proposed approach is the incentive mechanism, which is a solution to increase client motivatability. There is no obligation for data or device owners to join the training process if there are no benefits for them to contribute their data and resources. Incentive mechanisms can attract data and device owners to join the model training. Incentives can be given based on the amount of computation, communication, and energy resources provided [80, 165], the local model performance [107], the quality of the data provided [194], the honest behavior of client devices [130], and the dropout rate of a client node [125]. The proposed incentive mechanisms can be hosted by either a central server [75, 196] or a blockchain [79, 105].
Resource management is introduced to control and optimize computation resources, bandwidth, and energy consumption of participating devices in a training process to address system heterogeneity [121, 168] and communication efficiency [4, 141]. The proposed approaches use control algorithms [168], reinforcement learning [118, 193], and edge computing methods [121] to optimise the resource usage and improve the system efficiency. To address communication efficiency, model compression methods are utilised to reduce the data size and lower the communication cost that occurs during the model updates [22, 38, 82, 90, 142, 167]. Furthermore, model compression can also promote scalability as it is applicable to bandwidth limited and latency-sensitive scenarios [142].
Privacy preservation methods are introduced to maintain (1) data security: prevents information (model parameters or gradients) leakage to unauthorised parties, and (2) client devices security: prevents the system from being compromised by dishonest nodes. One well-cited method used for data security maintenance is differential privacy [139, 178], such as gaussian noise addition to the features before model updates [109]. For client device security maintenance, secure multiparty computations method such as homomorphic encryption is used together with local differential privacy method [139, 158, 178]. While homomorphic encryption only allows the central server to compute the global model homomorphically based on the encrypted local updates, the local differential privacy method protects client data privacy by adding noise to model parameter data sent by each client [158]. Security protection method is also proposed to solve the issues for both client device security [100, 102, 175] and data security [55, 198], which includes encrypting model parameters or gradients prior to exchanging the models between the server and client nodes.
Communication coordination methods are introduced to improve communication efficiency [65, 182] , and system performance [34]. Specifically, communication techniques such as multi-channel random access communication [34] or over-the-air computation methods [6, 182] enable wireless federated training process to achieve faster convergence.

J. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2020.

A Systematic Literature Review on Federated Machine Learning: From A Software Engineering Perspective

111:17

Fig. 7. RQ 3: How are the federated learning challenges being addressed?
To address the model performance issues [64], statistical heterogeneity problems [161], system auditability limitations [164] and communication efficiency limitations [189], feature fusion or selection methods are used. Feature selection methods are used to improve the convergence rate [64] by only aggregating models with the selected features. Feature fusion is used to reduce the impact of non-IID data on the model performance [161]. Moreover, the feature fusion method reduces the dimension of data to be transferred to speed up the training process and increases the communication efficiency [189]. [164] proposed a feature separation method that measures the importance level of the feature in the training process, used for system interpretation and auditing purposes.
Data provenance mechanisms are used to govern the data and information interactions between nodes. They are effective in preventing single-point-of-failures and adversarial attacks that intend to tamper the data. One way to implement a data provenance mechanism in a federated learning system is through blockchains. Blockchains record all the events instead of the raw data for audit and data provenance, and only permits authorised parties to access the information [105, 191]. Furthermore, blockchains are used for incentive provisions in [14, 79, 80, 171], also for storing global model updates in Merkle trees [110].
Data augmentation methods are introduced to address data security [128, 155] and client device security issues [124]. The approaches use privacy-preserving generative adversarial network (GAN) models to locally reproduce the data samples of all devices [68] for data release [155] and debugging processes [10]. These methods provide extra protection to shield the actual data from exposure. Furthermore, data augmentation methods are also effective in solving statistical heterogeneity issues through reproduction of an IID dataset for better training performance [68].
Auditing mechanisms are proposed as a solution for the lack of system auditability and client device security limitations. They are responsible for assessing the honest or semi-honest behavior of a client node during training and detecting any anomalies [10, 80, 201]. Some researchers have also introduced anomaly detection mechanisms [48, 94, 130], specifically to penalise adversarial or misbehaving nodes.
To properly assess the behavior of a federated learning system, some researchers have proposed evaluation mechanisms. The mechanisms are intended to solve the system auditability and statistical heterogeneity issues. For instance, in [170], a visualisation platform to illustrate the federated learning system is presented. In [21], a benchmarking platform is presented to realistically capture the characteristics of a federated scenario. Furthermore, [61] introduces a method to measure the performance of the federated averaging algorithm.
J. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2020.

111:18

J. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2020.

Table 14. What challenges of federated learning are being addressed (RQ 2) vs. How are the federated learning challenges being addressed (RQ 3)

Challenges vs Approaches

Model performance

Scalability

Statistical heterogeneity

System

System

auditability heterogeneity

Client motivatability

System reliability

Communication efficiency

System performance

Data security

Client device security

Model aggregation
Training management
Incentive mechanisms
Privacy preservation
Decentralised aggregation
Resource management
Security protection
Communication coordination Data augmentation
Model compression
Data provenance Evaluation Feature
fusion/selection Auditing
mechanisms Anomaly detection

[69]
-
-
-
-
[123] [64] -

[174],[135] -

[160],[190],[37], [116],[174],[29], [101],[113],[153], [127],[96],[17],
[77] [152],[66],[23], [141],[39],[82], [89],[71],[51], [54],[36],[149],
[53],[25]

-

[196]

-

-

[143]

-

-

-

-
[142] -

-
[42],[68]
[21],[61] [161] -

[8]
-
-
-
-
[19] [170] [164] [14],[10] -

[190],[41],[116],

[29],[194],[96], [18],[173],[122],

-

[17]

[28],[39],[89], [53]

[47]

[46],[140], [78]

[196],[80],[79], [171],[14],[75], [74],[46],[112],
[78],[165]

-

-

[110] -

[206],[32],[114],[131],[148], [207],[41],[103],[181],[180], [174],[29],[113],[68],[153],
[20],[135],[72],[52],[18], [17],[149],[83]
[188],[177],[197], [6],

-

[44],[126], [125]

-

-

[59]
[168],[121], [9],[179], [193],[187], [97],[7], [137],[195],
[92]
-
-
-
-
[21]
-
-
-

-

[79],[143],[86], [87],[63]

-

-

[59] [141],[4]

-

-

-

[182],[65],[5],

-

-

[27],[162],[147],

[6]

-

-

[202]

-

-

[167],[38], [142],[22], [82],[90]

-

-

-

-

-

-

-

-

[189]

-

-

-

-

-

-

[174],[29], [72]
-
-
-
[106]
-
[34]
-

[132],[18], [50]

[76],[129], [60],[30]

-

[152]

-

-

[106],[178],[11], [109],[152],[115], [139],[49],[91], [156],[16],[169]
[184]

[158],[70], [197],[35]
[144],[138], [184],[85],
[59]

-

-

[198],[55],[56], [175],[111],[104],
[58],[24],[33]

[175],[100], [102]

-

-

[155], [128]

[124],[201]

-

-

[105],[110],[191] -

[171],[107], [208],[203]
-
-

-

[14]

-

[130], [94], [48]

Lo, et al.

A Systematic Literature Review on Federated Machine Learning: From A Software Engineering Perspective

111:19

Findings of RQ 3: How are the federated learning challenges being addressed?
Top 5 proposed approaches: The top 5 proposed approaches are model aggregation, training management, incentive mechanisms, privacy-preserving methods, and resource management. These approaches mainly aim to solve issues such as communication efficiency, statistical and system heterogeneity, client motivatability, and data privacy.
Remaining proposed approaches: A few papers worked on anomaly detection, auditing mechanisms, feature fusion/selection, evaluation mechanisms and data provenance.
With regard to the software development lifecycle, this question contributes to the architecture design phase where we summarise different approaches proposed to address the identified requirements of federated learning systems.

Table 15. Summary of component designs

Sub-component
Anomaly detector Auditing mechanism Data provenance Client selector Communication coordinator Data augmentation Encryption mechanism Feature fusion mechanism Incentive mechanism Model aggregator Model compressor Model trainer Privacy preservation mechanism Resource manager Training manager

Client-based
7 4 3 6 2 211 1 2 1

Server-based
3 2 14 1 6 3 9 188 9 9

Both
12 6 14 -

3.8 RQ 3.1: What are the possible components of federated learning systems?
The motivation of RQ 3.1 is to identify the components in a federated learning system and their responsibilities. We classify the components of federated learning systems into 2 main categories: central server and client devices. A central server initiates and orchestrate the training process, whereas the client devices perform the actual model training [82, 113].
Apart from the central server and client devices, some studies added edge device to the system as an intermediate hardware layer between the central server and client devices. The edge device is introduced to increase the communication efficiency by reducing the training data sample size [72, 131] and increases the update speed [37, 101]. Table 15 summarises the number of mentions of each component. We classify them into client-based, server-based, or both to identify where these components are hosted. We can see that the model trainer is the most mentioned component for the client-based components, and model aggregator is mentioned the most in the server-based components. Furthermore, we notice that the software components that manage the system (e.g., anomaly detector, data provenance, communication coordinator, resource manager & client selector) are mostly server-based while the software components that enhance the model performance (e.g., feature fusion, data augmentation) are mostly client-based. Lastly, two-way operating software components such as model encryption, privacy preservation, and model compressor exist in both clients and the server.
3.8.1 Central server: Physically, the central servers are usually hosted on a local machine [88, 192], cloud server [56, 154, 177], mobile edge computing platform [121], edge gateway [146, 205] or base station [9, 65, 106, 182]. The central server is a hardware component that creates the first global model by randomly initialises the model parameters or gradient[27, 55, 88, 113, 114, 199].
J. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2020.

111:20

Lo, et al.

Besides randomising the initial model, central servers can pre-train the global model, either using a self-generated sample dataset or a small amount of data collected from each client device [131, 132]. We can define this as the server-initialised model training setting. Note that not all federated learning systems initialise their global model on the central server. In decentralised federated learning, clients initialise the global model [14, 110, 143].
After global model initialisation, the central servers broadcast the global model that includes the model parameters or gradients to the participating client devices. The global model can be broadcasted to all the participating client devices every round [5, 65, 142, 206], or only to specific client devices, either randomly [32, 88, 114, 159, 182] or through selection based on the model training performance [131, 179] and the resources availability [38, 168]. Similarly, the trained local models are also collected from either all the participating client devices [167, 168, 198] or only from selected client devices [19, 111]. The collection of models can either be in an asynchronous [29, 64, 99, 174] or synchronous manner [42, 48]. Finally, the central server performs model aggregations when it receives all or a specific amount of updates, followed by the redistribution of the updated global model to the client devices. This entire process continues until convergence is achieved.
Apart from orchestrating the model parameters and gradients exchange, the central server also hosts other software components, such as encryption/decryption mechanisms for model encryption and decryption [11, 19, 111], and resource management mechanisms to optimise the resource consumption [9, 121]. Evaluation framework is proposed to evaluate the model and system performance [21, 61, 170], while the client and model selector is introduced to select appropriate clients for model training and select high quality models for global aggregation [38, 131, 168, 179]. Feature fusion mechanisms are proposed to combine essential model features and reduces communication cost [64, 161, 164, 189]. Incentive mechanisms are utilised to motivate the clients’ participation rate [46, 78, 125, 126, 140, 165, 196]. An anomaly detector is introduced to detect system anomaly [48], while the model compressor compresses the model to reduce the data size [22, 38, 82, 142, 167]. Communication coordinator manages the multi-channel communication between the central server and client devices [5, 6, 27, 65, 147, 162, 182]. Lastly, auditing mechanisms audit the training processes [10, 14, 14, 201].
3.8.2 Client devices: The client devices are the hardware component that conducts model training using the locally available datasets. Firstly, each client device collects and pre-processes the local data (data cleaning, labeling, feature extraction, etc.). All client devices receive the initial global model and initiates the operations. The client devices decrypts and extracts the global model parameters. After that, they perform local model training. The received global model is also used for data inference and prediction by the client devices.
The local model training minimises the loss function and optimises the local model performance. Typically, the model is trained for multiple rounds and epochs [113], before being uploaded back to the central server for model aggregations. To reduce the number of communication rounds, [52] proposed to perform local training on multiple local mini-batch of data. The method only communicates with the central server after the model achieved convergence.
After that, the client devices send the training results (model parameters or gradients) back to the central server. Before uploading, client devices evaluate the local model performance and only upload when an agreed level of performance is achieved [61]. The results are encrypted using the encryption mechanism before uploading to preserve the data security and prevent information leakage [11, 19, 111]. Furthermore, the model is compressed before uploaded to the central server to reduce communication cost [22, 38, 82, 142, 167]. In certain scenarios, not all devices are required to upload their results. Only the selected client devices are required to upload the results, depending on the selection criteria set by the central server. The criteria evaluates the available resources

J. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2020.

A Systematic Literature Review on Federated Machine Learning: From A Software Engineering Perspective

111:21

of the client devices and the model performance [9, 121, 193]. The client devices can host data augmentation mechanism [68, 155], and feature fusion mechanisms that correlate to the central server in the same federated learning systems. After the completion of one model training round, the training result is uploaded to the central server for global aggregation.
For decentralised federated learning systems, the client devices communicate among themselves without the orchestration of the central server. The removed central server is mostly replaced by a blockchain as a software component for model and information provenance [11, 14, 74, 79, 80, 105, 110, 171]. The blockchain is also responsible for incentive provision and differential private multiparty data model sharing. The initial model is created locally by each client device using local datasets. The models are updated using a consensus-based approach that enables devices to send model updates and receive gradients from neighbour nodes [85, 87, 143]. The client devices are connected through a peer-to-peer network [63, 138, 144]. Each device has the model update copies of all the client devices. After reaching consensus, all the client devices will conduct model training using the new gradient.
In cross-device settings, the system has a high client device population where each device is the data owner. In contrast, in the cross-silo setting, the client network is formed by several companies or organisations, regardless of the number of individual devices they own. The number of data silos is significantly smaller compared to the cross-device setting [73]. Therefore, the cross-device system creates models for large-scale distributed data on the same application [160], while the cross-silo system creates models to accommodate data that is heterogeneous in terms of its content and semantic in both features and sample space [160]. The data partitioning is also different. For the cross-device setting, the data is partitioned automatically by example (horizontal data partitioning). The data partitioning of cross-silo setting is fixed either by feature (vertical) or by example (horizontal) [73].

Findings of RQ 3.1: What are the possible components of federated learning? Mandatory components (clients): data collection, data preprocessing, feature engineering, model training, and inference. Mandatory components (server): model aggregation, evaluation. Optional components (clients): anomaly detection, model compression, auditing mechanisms, data augmentation, feature fusion/selection, security protection, privacy preservation, data provenance. Optional components (server): advanced model aggregation, training management, incentive mechanism, resource management, communication coordination. With regard to the software development lifecycle, this question contributes to the architecture design phase where we discuss the roles, responsibilities, and the interactions of the different components from an architecture design perspective.
*Mandatory components - Components that perform the main federated learning operations.
*Optional components - Components that assist/enhance the federated learning operations.

3.9 RQ 3.2: What are the phases of the machine learning pipeline covered by the research activities?
Table 16 presents a summary of machine learning pipeline phases covered by the studies. Notice that only phases that are specifically elaborated in the papers are included. The top 3 most mentioned machine learning phases are "model training" (161 mentions), followed by "data collection" (22 mentions) and "data cleaning" (18 mentions). These 3 stages of federated learning are mostly similar to the approaches in conventional machine learning systems. The key differences are the distributed model training tasks, decentralised data storage, and non-IID data distribution. Notice
J. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2020.

111:22

Lo, et al.

that only Google mentioned model inference and deployment, specifically for Google keyboard applications. The on-device inference supported by TensorFlow Lite is mentioned in [57, 134], and [185] mentioned that a model checkpoint from the server is used to build and deploy the on-device inference model. It uses the same featurisation flow which originally logged training examples on-device. However, the deployed model monitoring (e.g., dealing with performance degradation) and project management (e.g., model versioning) are not discussed in the existing studies. We infer that federated learning research is still in an early stage as most researchers focused on the data-processing and model training optimisation.

Findings of RQ 3.2: What are the phases of the machine learning pipeline covered by the research activities?
Phases: The model training phase is most discussed. Only a few studies expressed data pre-processing, feature engineering, model evaluation, and only Google has discussions about model deployment (e.g., deployment strategies) and model inference. Model monitoring (e.g., dealing with performance degradation), and project management (e.g., model versioning) are not discussed in the existing studies. More studies are needed for the development of productionlevel federated learning systems.
With regard to the software development lifecycle, this question contributes to the background understanding phase where we identify the machine learning pipeline phases focused by the federated learning studies.

Table 16. Summary of machine learning pipeline phases

ML pipeline
Paper count

Data collection
22

Data cleaning
18

Data labelling
13

Data augmentation
9

Feature engineering
8

Model training
161

Model evaluation
10

Model deployment
1

Model inference
2

3.10 RQ 4: How are the approaches evaluated?
RQ 4 focuses on the evaluation approaches in the studies. We classify the evaluation approaches into two main groups: simulation and case study. For the simulation approach, image processing is the most common task, with 99 out of 197 cases, whereas the most implemented use cases are applications on mobile devices (11 out of 17 cases), such as word suggestion and human activity recognition.

Table 17. Evaluation approaches for federated learning

Evaluation methods Simulation (85%)
Case study (7%)
Both (1%) No evaluation (7%)

Application types
Image processing Others
Mobile device applications Healthcare Others
Image processing Mobile device applications
-

Paper count
99 98
11 3 3
1 1
15

J. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2020.

A Systematic Literature Review on Federated Machine Learning: From A Software Engineering Perspective

111:23

Findings of RQ 4: How are the approaches evaluated?
Evaluation: Researchers mostly evaluate their federated learning approaches by simulation using privacy-sensitive scenarios. There are only a few real-world case studies, e.g., Google’s mobile keyboard prediction.
With regard to the software development lifecycle, this question contributes to the implementation and evaluation phase where we explore the different methods to evaluate the federated learning approaches.

3.11 RQ 4.1: What are the evaluation metrics used to evaluate the approaches?
Through RQ 4.1, we intend to identify the evaluation metrics for both qualitative and quantitative methods adopted by federated learning systems. We explain how each evaluation metric is used to assess the system and map these metrics to the quality attributes mentioned in RQ 2. The results are summarised in Table 18.
First, the communication efficiency is evaluated by communication cost, dropout ratio, model performance, and system running time. The communication cost is quantified by the communication rounds against the learning accuracy [32, 34, 103, 107, 114, 151, 167], the satisfying rate of communications [199], communication overhead versus number of clients [56, 181], the theoretical analysis of communication cost of data interchange between the server and clients [19, 150, 157], data transmission rate [175, 178], bandwidth [133, 193], and latency of communication [79]. The dropout ratios are measured by the computation overhead against dropout ratios [122, 175]. The results are showcased as the comparison between communication overhead for different dropout rates [175], and the performance comparison against dropout rate [29, 96, 104].
Secondly, the model performance is measured by the training loss [25, 103, 151], AUC-ROC value [103, 105, 184], F1-score [13, 29, 43], root-mean-squared error (RMSE) [26, 148], crossentropy [45, 174], precision [43, 186, 200], recall [43, 186, 200], prediction error [83, 149], mean absolute error [64], dice coefficient [145], and perplexity value [141].
Thirdly, the system scalability is evaluated by communication cost and system running time. For the system running time evaluation, the results are presented as the total execution time of the training protocol (computation time & communication time) [104, 105, 117, 175, 198], the running time of different operation phases [198], the running time of each round against the number of client devices [19, 121, 130], and the model training time [171, 178].
The system performance is evaluated in multiple aspects, including system security (e.g., attack rate), scalability (e.g., communication and computation costs, dropout ratio), and system reliability (e.g., convergence rate, model performance, and system running time). The attack rate is measured as the proportion of attack targets that are incorrectly classified as the target label [48]. Essentially, researchers use this metric to evaluate how effective the defence mechanisms are [47, 117, 144, 201]. The types of attack are model poisoning attack, sybil attack, byzantine attack, and data reconstruction attack. Computation cost is the assessment of computation, storage, and energy resource usage of a system. The computation resources are quantified by the computation overhead against the number of client devices [55, 115, 122, 193], average computation time [72, 92, 187], computation throughput [9, 171], computation latency [79], computation utility, and the overhead of components [25, 196]. The storage resources are evaluated by the memory and storage overhead [42, 111, 122], and storage capacity [133]. The energy resources are calculated by the energy consumption for communication [46, 101], the energy consumption against computation time [92, 101, 146, 179, 187], and the energy consumption against training dataset size [209]. Lastly, the convergence rate is quantified by the accuracy versus the communication rounds, system running time, and training data epochs [15, 140, 189].
For statistical and system heterogeneity, qualitative analyses are conducted to verify if the proposed approaches have satisfied their purpose of addressing the limitations. The statistical
J. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2020.

111:24

Lo, et al.

Table 18. Quality Attributes vs Evaluation Metrics

Quality attributes
vs Evaluation
metrics

Communication efficiency

Model performance

Scalability

System performance

Statistical heterogeneity

System heterogeneity

Client motivatability

Data security

Client device security

Attack rate

-

-

-

1

-

-

-

1

4

Communication cost

58

-

3

2

-

-

-

-

-

Computation cost

-

-

-

42

-

-

-

-

-

Convergence rate

-

-

-

15

-

-

-

-

Dropout ratio

1

-

-

2

-

2

-

1

-

Incentive rate

-

-

-

-

-

-

6

-

-

Model performance

1

253

-

1

-

-

2

-

-

Privacy loss

-

-

-

-

-

-

-

2

-

System running time

2

-

2

20

-

-

-

-

-

Qualitative evaluation

-

-

-

-

3

1

-

7

4

heterogeneity is evaluated through formal verification such as model and equation proving [77, 116, 174], whereas system heterogeneity is evaluated by the dropout ratio due to the limited resource and also formal verification through equation proving [116].
Client motivatability is measured by the incentive rate against different aspects of the system. The incentive rate is assessed by calculating the profit of the task publisher under different numbers of clients or accuracy levels [74], the average reward based on the model performance [204], and the relationship between the offered reward rate and the local accuracy over the communication cost [78, 125, 126]. From the studies collected, there is no mention of any specific form of rewards provided as incentives. However, cryptocurrencies such as Bitcoin or tokens which can be converted to actual money are common kinds of rewards.
Finally, both data security and client device security are measured by the attack rates and other respective qualitative evaluation metrics. Essentially, the data security analyses include analysis of encryption and verification process performance [16, 50, 56], the differential privacy achievement [105, 106], the effect of the removal of centralised trust [105], and the guarantee of shared data quality [105]. The client device security analyses are the performance of encryption and verification process [102, 175, 184], the confidentiality guarantee for gradients, the auditability of gradient collection and update, and the fairness guarantee for model training [171]. Also, the data security is measured by privacy loss, which evaluates the privacy-preserving level of the proposed method [204], derived from the differential average-case privacy [155].

Findings of RQ 4.1: What are the evaluation metrics used to evaluate the approaches?
Evaluation: Both quantitative and qualitative analysis are used to evaluate the federated learning system. Quantitative metrics examples: Model performance, communication & computation cost, system running time, etc. Qualitative metrics examples: Data security analysis on differential privacy achievement, Performance of encryption and verification process, confidentiality guarantee for gradients, the auditability of gradient collection and update, etc. With regard to the software development lifecycle, this question contributes to the implementation and evaluation phase where we identify the different evaluation metrics used to assess the quality attributes of the federated learning systems.

3.12 Summary We have presented all the findings and results extracted through each RQ. We summarise all the findings in a mind-map, as shown in Fig. 9.
J. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2020.

A Systematic Literature Review on Federated Machine Learning: From A Software Engineering Perspective

111:25

Fig. 8. Open problems and future research trends highlighted by existing reviews/surveys
4 OPEN PROBLEMS AND FUTURE TRENDS IN FEDERATED LEARNING
In this section, we discuss the open problems and future research trends from the survey and review papers we collected to provide unbiased analyses (refer Table 19). The findings are shown in Fig. 8 and the detailed explanations are elaborated below:
• Enterprise and industrial-level implementation. Being at the early stage of research [73, 93, 95, 98, 176], the only mentions of enterprise federated learning systems are the cross-silo settings and some possible applications on real-world use cases listed in Table 10. The possible challenges are as follow: – Machine learning pipeline: Most existing studies in federated learning focus on the federated model training phase, without considering other machine learning pipeline stages (e.g., model deployment and monitoring) under the context of federated learning (e.g., new data lifecycles) [93, 95, 98, 176]. – Benchmark: Benchmarking schemes are needed to evaluate the system development under real-world settings, with rich datasets and representative workload [73, 93, 95]. – Dealing with unlabeled client data: In practice, the data generated on clients may be mislabeled or unlabeled [73, 93, 95, 98]. Some possible solutions are semi-supervised learning-based techniques, labeling the client data by learning the data label from other clients. However, these solutions may require dealing with the data privacy, heterogeneity, and scalability issues. – Software architecture: Federated learning still lacks systematic architecture design to guide methodical system development. A systematic architecture can provide design or algorithm alternatives for different system settings [93]. – Regulatory compliance: The regulatory compliance issues for federated learning systems is under-explored [93] (e.g., whether data transfer limitations in GDPR is applied to model update transfer, ways to execute right-to-explainability to the global model, and whether the global model should be retrained if a client wants to quit). Machine learning and law enforcement communities are expected to cooperate to fill the gap between federated learning technology and the regulations in reality. – Human-in-the-loop: Domain experts are expected to be involved in the federated learning process to provide professional guidance as end-users tend to trust the expert’s judgement more than the inference by machine learning algorithms. [176].
J. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2020.

111:26

Lo, et al.

Data security analysis Client device security
analysis System/statistical heterogeneity analysis Decentralised trust
analysis
Communication cost Convergence rate Dropout ratio

Qualitative evaluation
metrics
Implementation & Evaluation

Deﬁnition

Training settings
Data characteristics
Client types

Central orchestration
Model training on multiple clients
Local data generation Decentralised data storage No raw data exchange
Cross-device
Cross-silo

Incentive rate Model performance Privacy loss

Quantitative evaluation
metrics

System running time

Attack rate

Computation cost

Model aggregation
Evaluation

Mandatory components

Central server

Training management Incentive mechanism Resource management
Communication coordinator

Optional components

Adoption objectives

Background Understanding

Federated Learning System Development

Application types
Data types

Advanced model aggregation: decentralised, selective, etc.
Data collection

Architecture Design

Data pre-processing Feature engineering Model training

Mandatory components

Machine learning pipeline

Model inference Anomaly detection

Client device

Data partitioning
Data privacy
Scalability
Model performance

Vertical
Horizontal Transfer learning
Communication /computation efﬁciency
Statistical /system heterogeneity
Data storage

Privacy-sensitive applications: Image classiﬁcation, keyboard prediction, etc.

Graph data Image data
Sequential data Structured data
Text data Time-series data

Data collection Data labelling

Data cleaning

Data augmentation

Feature engineering

Model training Model evaluation
Model deployment

Model inference

Model performance

Model compression

Communication efﬁciency

Data provenance Auditing mechanism Data augmentation

Optional components

Requirements

Statistical/system heterogeneity Data security
Client device security

Privacy preservation

System reliability

Feature fusion/selection Security protection

Requirement Analysis

System performance System auditability
Scalability

Identically & Independently Distribution (I.I.D)

Data distributions

Non-Identically & Independently Distribution
(Non- I.I.D)

Fig. 9. Mind-map summary of the findings J. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2020.

A Systematic Literature Review on Federated Machine Learning: From A Software Engineering Perspective

111:27

• Advanced privacy preservation methods: More advanced privacy preservation methods are needed as the existing solutions still can reveal sensitive information [73, 93, 95, 98, 108, 120]. – Tradeoffs between data privacy and model system performance: The current approaches (e.g., differential privacy and collaborative training) sacrifice the model performance, and require significant computation cost [98, 108, 120]. Hence, the design of federated learning systems needs to balance the tradeoffs between data privacy and model/system performance. – Granular privacy protection: In reality, privacy requirements may differ across clients or across data samples on a single client. Therefore, it is necessary to protect data privacy in a more granular manner. Privacy heterogeneity should be considered in the design of federated learning systems for different privacy requirements (e.g., client device-specific or sample data specific). One direction of future work is extending differential privacy with granular privacy restriction (e.g., heterogeneous differential privacy) [93, 95, 108]. – Sharing of less sensitive model data: Devices should only share less sensitive model data (e.g., inference results or signSGD), and this type of approaches may be considered in future work [73, 108].
• Improving system and model performance. There are still some performance issues regarding federated learning systems, mainly on resource allocation (e.g., communication, computation, and energy efficiency). Moreover, model performance improvement through the non-algorithm or non-gradient optimisation approach (e.g., promoting more participants, the extension of the federated model training method) is also another future research trend. – Handling of client dropouts: In practice, participating clients may drop out from the training process due to energy constraints or network connectivity issues [73, 93, 98]. A large number of client dropouts can significantly degrade the model performance. Many of the existing studies do not consider the situation when the number of participating clients changes (i.e., departures or entries of clients). Hence, the design of a federated learning system should support the dynamic scheduling of model updates to tolerate client dropouts. Furthermore, new algorithms are needed to deal with the scenarios where only a small number of clients are left in the training rounds. The learning coordinator should provide stable network connections to the clients to avoid dropouts. – Advanced incentive mechanisms: Without a well-designed incentive mechanism, potential clients may be reluctant to join the training process, which will discourage the adoption of federated learning [73, 93, 176]. In most of the current designs, the model owner pays for the participating clients based on some metrics (e.g., number of participating rounds or data size), which might not be effective in evaluating the incentive provision. – Model markets: A possible solution proposed to promote federated learning applications is the model market [93]. One can perform model prediction using the model purchased from the model market. In addition, the developed model can be listed on the model market with additional information (e.g., task, domain) for federated transfer learning. – Combined algorithms for communication reduction: The method to combine different communication reduction techniques (combining model compression technique with local updating) is an interesting direction to further improve the system’s communication efficiency (e.g., optimise the size of model updates and communication instances) [73, 95, 98]. However, the feasibility of such a combination is still under-explored. In addition, the tradeoffs between model performance and communication efficiency are needed to be further examined (e.g., how to manage the tradeoffs under the change of training settings?).

J. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2020.

111:28

Lo, et al.

– Asynchronous federated learning: Synchronous federated learning may have efficiency issues caused by stragglers. Asynchronous federated learning has been considered as a more practical solution, even allowing clients to participate in the training halfway [73, 95, 98]. However, new asynchronous algorithms are still under explored to provide convergence guarantee.
– Statistical heterogeneity quantification: The quantification of the statistical heterogeneity into metrics (e.g., local dissimilarity) is needed to help improve the model performance for non-IID condition [95, 98]. However, the metrics can hardly be calculated before training. One important future direction is the design of efficient algorithms to calculate the degree of statistical heterogeneity that is useful for model optimisations.
– Multi-task learning: Most of the existing studies focus on training the same model on multiple clients. One interesting direction is to explore how to apply federated learning to train different models in the federated networks [73, 108].
– Decentralised learning: As mentioned above, decentralised learning does not require a central server in the system [73, 108], which prevents single-point-of-failure. Hence, it would be interesting to explore if there is any new attack or whether federated learning security issues still exist in this setting.
– One/few shot learning: Federated learning that executes less training iterations, such as one/few-shot learning, has been recently discussed for federated learning [73, 95]. However, more theoretical and empirical studies are needed in this direction.
– Federated transfer learning: For federated transfer learning, there are only 2 domains or data parties are assumed in most of the current literature. Therefore, expanding federated transfer learning to multiple domains, or data parties is an open problem [73].
5 THREATS TO VALIDITY
We identified the threats to validity that might influence the outcomes of our research. First, publication bias exists as most studies have positive results rather than negative results. While studies with positive results are much appealing to be published in comparison with studies with no or negative results, a tendency towards certain outcomes might leads to biased conclusions. The second threat is the exclusion of the studies which focus on pure algorithm improvements. The exclusion of respective studies may affect the completeness of this research as some discussion on the model performance and data heterogeneity issues might be relevant. The third threat is the incomplete search strings in the automatic search. We included all the possible supplementary terms related to federated learning while excluding keywords that return conventional machine learning publications. However, the search terms in the search strings may still be insufficient to search all the relevant work related to federated learning research topics. The fourth threat is the exclusion of ArXiv and Google Scholar papers which are not cited by peer-reviewed papers. The papers from these sources are not peer-reviewed and we cannot guarantee the quality of these research works. However, we want to collect as many state-of-the-art studies in federated learning as possible. To maintain the quality of the search pool, we only include papers that are cited by peer-reviewed papers. The fifth threat is the time span of research works included in this systematic literature review. We only included papers published from 2016.01.01 to 2020.01.31. Since the data in 2020 does not represent the research trend of the entire year, we only include works from 2016 to 2019 for the research trend analysis (refer to Fig. 6). However, the studies collected in only January 2020 is equally significant to those from the previous years for identifying challenges and solutions. Hence, we keep the findings from the papers published in 2020 for the remaining discussions. The sixth threat is the study selection bias. To avoid the study selection bias between the 2 researchers, the cross-validation of the results from the pilot study is performed by the two

J. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2020.

A Systematic Literature Review on Federated Machine Learning: From A Software Engineering Perspective

111:29

independent researchers prior to the update of search terms and inclusion/exclusion criteria. The mutual agreement between the two independent researchers on the selections of paper is required. When a dispute on the decision occurs, the third researcher is consulted. Lastly, there might be bias in data collection and analysis due to different background and experience of the researchers.
6 RELATED WORK
According to the protocol, we collected all the relevant surveys and reviews. There are 7 surveys and 1 review that studied the federated learning topic. To the best of our knowledge, there is still no systematic literature review conducted on federated learning.
Li et al. [93] propose a federated learning building blocks taxonomy that classifies the federated learning system into 6 aspects: data partitioning, machine learning model, privacy mechanism, communication architecture, the scale of the federation, and the motivation of federation. Kairouz et al. [73] present a general survey on the advancement in research trends and the open problems suggested by researchers. Moreover, the paper covered detailed definitions of federated learning system components and different types of federated learning systems variations. Li et al. [95] present a review on federated learning’s core challenges of federated learning in terms of communication efficiency, privacy, and future research directions. Surveys on federated learning systems for specific research domains are also conducted. Niknam et al. [120] review federated learning in the context of wireless communications. The survey mainly investigates the data security and privacy challenges, algorithm challenges, and wireless setting challenges of federated learning systems. Lim et al. [98] discuss federated learning papers in the mobile edge network. Lyu et al.[108] focus on the security threats and vulnerability challenges in federated learning systems whereas Xu and Wang [176] explore the healthcare and medical informatics domain. A review of federated learning that focuses on data privacy and security aspects was conducted by [183].
The comparisons of each survey and review papers with our systematic literature review are summarised in Table 19. We compare our work with the existing works in 4 aspects: (1) Time frames: our review on the state-of-the-art is the most contemporary as it is the most up-to-date review. (2) Methodology: we followed Kitchenham’s standard guideline [81] to conduct this systematic literature review. Most of the existing works have no clear methodology, where information is collected and interpreted with subjective summaries of findings that may be subject to bias. (3) Comprehensiveness: the number of papers analysed in our work is higher than the existing reviews or surveys as we screened through relevant journals and conferences paper-by-paper. (4) Analysis: we provided 2 more detailed review on federated learning approaches, including (a) the context of studies (e.g., publication venues, year, type of evaluation metrics, method, and dataset used) for the state-of-the-art research identification and (b) the data synthesis of the findings through the lifecycle of federated learning systems.
Table 19. Comparison with existing reviews/surveys on federated learning

Paper
This study Yang et al. (2019) [183] Kairouz et al. (2019) [73] Li et al. (2020) [93] Li et al. (2019) [95] Niknam et al. (2020) [120] Lim et al. (2020) [98] Lyu et al. (2020) [108] Xu and Wang (2019) [176]

Type
SLR Survey Survey Survey Survey Review Survey Survey Survey

Time frames
2016-2020 2016-2018 2016-2019 2016-2019 2016-2020 2016-2019 2016-2020 2016-2020 2016-2019

Methodology
SLR guideline [81] Undefined Undefined Customised Undefined Undefined Undefined Undefined Undefined

Scoping
Software engineering perspective General overview General overview System view General overview
Wireless communications Mobile edge networks Vulnerabilities Healthcare informatics

J. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2020.

111:30

Lo, et al.

7 CONCLUSION
Federated learning has attracted a broad range of interests from academia and industry. We performed a systematic literature review on federated learning from the software engineering perspective with 231 primary studies. The results show that most of the known motivations for using federated learning appear to be also the most studied research challenges in federated learning. To tackle the challenges, the top five proposed approaches are model aggregation, training management, incentive mechanism, privacy preservation, and resource management. The research findings provide clear viewpoints on federated learning system development for production adoption. Finally, this paper sheds some light on the future research trends of federated learning and encourages researchers to extend and advance their current work.

REFERENCES
[1] 2008. ISO/IEC 25012. https://iso25000.com/index.php/en/iso-25000-standards/iso-25012 [2] 2011. ISO/IEC 25010. https://iso25000.com/index.php/en/iso-25000-standards/iso-25010 [3] 2019. General Data Protection Regulation GDPR. https://gdpr-info.eu/ [4] Mehdi Salehi Heydar Abad, Emre Ozfatura, Deniz Gunduz, and Ozgur Ercetin. 2019. Hierarchical federated learning
across heterogeneous cellular networks. arXiv preprint arXiv:1909.02362 (2019). [5] J. Ahn, O. Simeone, and J. Kang. 2019. Wireless Federated Distillation for Distributed Edge Learning with Heteroge-
neous Data. In 2019 IEEE 30th Annual International Symposium on Personal, Indoor and Mobile Radio Communications (PIMRC). 1–6. [6] Mohammad Mohammadi Amiri and Deniz Gunduz. 2019. Federated learning over wireless fading channels. arXiv preprint arXiv:1907.09769 (2019). [7] Mohammad Mohammadi Amiri, Deniz Gunduz, Sanjeev R. Kulkarni, and H. Vincent Poor. 2020. Update Aware Device Scheduling for Federated Learning at the Wireless Edge. arXiv:2001.10402 [cs.IT] [8] Vito Walter Anelli, Yashar Deldjoo, Tommaso Di Noia, and Antonio Ferrara. 2019. Towards Effective Device-Aware Federated Learning. Springer International Publishing, Cham, 477–491. [9] T. T. Anh, N. C. Luong, D. Niyato, D. I. Kim, and L. Wang. 2019. Efficient Training Management for Mobile CrowdMachine Learning: A Deep Reinforcement Learning Approach. IEEE Wireless Communications Letters 8, 5 (Oct 2019), 1345–1348. [10] Sean Augenstein, H. Brendan McMahan, Daniel Ramage, Swaroop Ramaswamy, Peter Kairouz, Mingqing Chen, Rajiv Mathews, and Blaise Aguera y Arcas. 2019. Generative Models for Effective ML on Private, Decentralized Datasets. arXiv:1911.06679 [cs.LG] [11] Sana Awan, Fengjun Li, Bo Luo, and Mei Liu. 2019. Poster: A Reliable and Accountable Privacy-Preserving Federated Learning Framework using the Blockchain. In Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security. Association for Computing Machinery, London, United Kingdom, 2561–2563. [12] U. M. Aïvodji, S. Gambs, and A. Martin. 2019. IOTFLA : A Secured and Privacy-Preserving Smart Home Architecture Implementing Federated Learning. In 2019 IEEE Security and Privacy Workshops (SPW). 175–180. [13] Evita Bakopoulou, Balint Tillman, and Athina Markopoulou. 2019. A federated learning approach for mobile packet classification. arXiv preprint arXiv:1907.13113 (2019). [14] X. Bao, C. Su, Y. Xiong, W. Huang, and Y. Hu. 2019. FLChain: A Blockchain for Auditable Federated Learning with Trust and Incentive. In 2019 5th International Conference on Big Data Computing and Communications (BIGCOM). 151–159. [15] Daniel Benditkis, Aviv Keren, Liron Mor-Yosef, Tomer Avidor, Neta Shoham, and Nadav Tal-Israel. 2019. Distributed deep neural network training on edge devices. In Proceedings of the 4th ACM/IEEE Symposium on Edge Computing. Association for Computing Machinery, Arlington, Virginia, 304–306. [16] Abhishek Bhowmick, John Duchi, Julien Freudiger, Gaurav Kapoor, and Ryan Rogers. 2018. Protection against reconstruction and its applications in private federated learning. arXiv preprint arXiv:1812.00984 (2018). [17] Keith Bonawitz, Hubert Eichner, Wolfgang Grieskamp, Dzmitry Huba, Alex Ingerman, Vladimir Ivanov, Chloe Kiddon, Jakub Konecny, Stefano Mazzocchi, H Brendan McMahan, et al. 2019. Towards federated learning at scale: System design. arXiv preprint arXiv:1902.01046 (2019). [18] Keith Bonawitz, Vladimir Ivanov, Ben Kreuter, Antonio Marcedone, H Brendan McMahan, Sarvar Patel, Daniel Ramage, Aaron Segal, and Karn Seth. 2016. Practical secure aggregation for federated learning on user-held data. arXiv preprint arXiv:1611.04482 (2016).
J. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2020.

A Systematic Literature Review on Federated Machine Learning: From A Software Engineering Perspective

111:31

[19] Keith Bonawitz, Vladimir Ivanov, Ben Kreuter, Antonio Marcedone, H. Brendan McMahan, Sarvar Patel, Daniel Ramage, Aaron Segal, and Karn Seth. 2017. Practical Secure Aggregation for Privacy-Preserving Machine Learning. In Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security. Association for Computing Machinery, Dallas, Texas, USA, 1175–1191.
[20] Keith Bonawitz, Fariborz Salehi, Jakub Konečny`, Brendan McMahan, and Marco Gruteser. 2019. Federated learning with autotuned communication-efficient secure aggregation. arXiv preprint arXiv:1912.00131 (2019).
[21] Sebastian Caldas, Sai Meher Karthik Duddu, Peter Wu, Tian Li, Jakub Konečný, H. Brendan McMahan, Virginia Smith, and Ameet Talwalkar. 2018. LEAF: A Benchmark for Federated Settings. arXiv:1812.01097 [cs.LG]
[22] Sebastian Caldas, Jakub Konečny, H Brendan McMahan, and Ameet Talwalkar. 2018. Expanding the Reach of Federated Learning by Reducing Client Resource Requirements. arXiv preprint arXiv:1812.07210 (2018).
[23] Sebastian Caldas, Virginia Smith, and Ameet Talwalkar. 2018. Federated Kernelized Multi-Task Learning. In SysML Conference 2018.
[24] Di Chai, Leye Wang, Kai Chen, and Qiang Yang. 2019. Secure Federated Matrix Factorization. arXiv:1906.05108 [cs.CR] [25] Fei Chen, Mi Luo, Zhenhua Dong, Zhenguo Li, and Xiuqiang He. 2018. Federated Meta-Learning with Fast Convergence
and Efficient Communication. arXiv:1802.07876 [cs.LG] [26] M. Chen, O. Semiari, W. Saad, X. Liu, and C. Yin. 2020. Federated Echo State Learning for Minimizing Breaks in
Presence in Wireless Virtual Reality Networks. IEEE Transactions on Wireless Communications 19, 1 (Jan 2020), 177–191. [27] Mingzhe Chen, Zhaohui Yang, Walid Saad, Changchuan Yin, H Vincent Poor, and Shuguang Cui. 2019. A joint learning and communications framework for federated learning over wireless networks. arXiv preprint arXiv:1909.07972 (2019). [28] Xiangyi Chen, Tiancong Chen, Haoran Sun, Zhiwei Steven Wu, and Mingyi Hong. 2019. Distributed Training with Heterogeneous Data: Bridging Median- and Mean-Based Algorithms. arXiv:1906.01736 [cs.LG] [29] Yujing Chen, Yue Ning, and Huzefa Rangwala. 2019. Asynchronous Online Federated Learning for Edge Devices. arXiv preprint arXiv:1911.02134 (2019). [30] Yudong Chen, Lili Su, and Jiaming Xu. 2018. Distributed Statistical Machine Learning in Adversarial Settings: Byzantine Gradient Descent. SIGMETRICS Perform. Eval. Rev. 46, 1 (2018), 96. https://doi.org/10.1145/3292040.3219655 [31] Yang Chen, Xiaoyan Sun, and Yaochu Jin. 2019. Communication-Efficient Federated Deep Learning with Asynchronous Model Update and Temporally Weighted Aggregation. arXiv:1903.07424 [cs.LG] [32] Y. Chen, X. Sun, and Y. Jin. 2019. Communication-Efficient Federated Deep Learning With Layerwise Asynchronous Model Update and Temporally Weighted Aggregation. IEEE Transactions on Neural Networks and Learning Systems (2019), 1–10. [33] Kewei Cheng, Tao Fan, Yilun Jin, Yang Liu, Tianjian Chen, and Qiang Yang. 2019. SecureBoost: A Lossless Federated Learning Framework. arXiv preprint arXiv:1901.08755 (2019). [34] J. Choi and S. R. Pokhrel. 2019. Federated Learning with Multichannel ALOHA. IEEE Wireless Communications Letters (2019), 1–1. [35] Olivia Choudhury, Aris Gkoulalas-Divanis, Theodoros Salonidis, Issa Sylla, Yoonyoung Park, Grace Hsu, and Amar Das. 2019. Differential Privacy-enabled Federated Learning for Sensitive Health Data. arXiv:1910.02578 [cs.LG] [36] Luca Corinzia and Joachim M Buhmann. 2019. Variational Federated Multi-Task Learning. arXiv preprint arXiv:1906.06268 (2019). [37] Harshit Daga, Patrick K. Nicholson, Ada Gavrilovska, and Diego Lugones. 2019. Cartel: A System for Collaborative Transfer Learning at the Edge. In Proceedings of the ACM Symposium on Cloud Computing. Association for Computing Machinery, Santa Cruz, CA, USA, 25–37. [38] K. Deng, Z. Chen, S. Zhang, C. Gong, and J. Zhu. 2019. Content Compression Coding for Federated Learning. In 2019 11th International Conference on Wireless Communications and Signal Processing (WCSP). 1–6. [39] Canh Dinh, Nguyen H Tran, Minh NH Nguyen, Choong Seon Hong, Wei Bao, Albert Zomaya, and Vincent Gramoli. 2019. Federated Learning over Wireless Networks: Convergence Analysis and Resource Allocation. arXiv preprint arXiv:1910.13067 (2019). [40] R. Doku, D. B. Rawat, and C. Liu. 2019. Towards Federated Learning Approach to Determine Data Relevance in Big Data. In 2019 IEEE 20th International Conference on Information Reuse and Integration for Data Science (IRI). 184–192. [41] Wei Du, Xiao Zeng, Ming Yan, and Mi Zhang. 2018. Efficient Federated Learning via Variational Dropout. (2018). [42] Moming Duan. 2019. Astraea: Self-balancing federated learning for improving classification accuracy of mobile deep learning applications. arXiv preprint arXiv:1907.01132 (2019). [43] S. Duan, D. Zhang, Y. Wang, L. Li, and Y. Zhang. 2019. JointRec: A Deep Learning-based Joint Cloud Video Recommendation Framework for Mobile IoTs. IEEE Internet of Things Journal (2019), 1–1. [44] Amin Fadaeddini, Babak Majidi, and Mohammad Eshghi. 2019. Privacy Preserved Decentralized Deep Learning: A Blockchain Based Solution for Secure AI-Driven Enterprise. Springer International Publishing, Cham, 32–40.

J. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2020.

111:32

Lo, et al.

[45] Zipei Fan, Xuan Song, Renhe Jiang, Quanjun Chen, and Ryosuke Shibasaki. 2019. Decentralized Attention-based Personalized Human Mobility Prediction. Proc. ACM Interact. Mob. Wearable Ubiquitous Technol. 3, 4 (2019), Article 133.
[46] S. Feng, D. Niyato, P. Wang, D. I. Kim, and Y. Liang. 2019. Joint Service Pricing and Cooperative Relay Communication for Federated Learning. In 2019 International Conference on Internet of Things (iThings) and IEEE Green Computing
and Communications (GreenCom) and IEEE Cyber, Physical and Social Computing (CPSCom) and IEEE Smart Data (SmartData). 815–820. [47] Clement Fung, Jamie Koerner, Stewart Grant, and Ivan Beschastnikh. 2018. Dancing in the Dark: Private Multi-Party Machine Learning in an Untrusted Setting. arXiv:1811.09712 [cs.CR] [48] Clement Fung, Chris JM Yoon, and Ivan Beschastnikh. 2018. Mitigating sybils in federated learning poisoning. arXiv preprint arXiv:1808.04866 (2018). [49] Robin C Geyer, Tassilo Klein, and Moin Nabi. 2017. Differentially private federated learning: A client level perspective. arXiv preprint arXiv:1712.07557 (2017). [50] Badih Ghazi, Rasmus Pagh, and Ameya Velingker. 2019. Scalable and Differentially Private Distributed Aggregation in the Shuffled Model. arXiv:1906.08320 [cs.LG] [51] Avishek Ghosh, Justin Hong, Dong Yin, and Kannan Ramchandran. 2019. Robust Federated Learning in a Heterogeneous Environment. arXiv preprint arXiv:1906.06629 (2019). [52] Neel Guha, Ameet Talwlkar, and Virginia Smith. 2019. One-Shot Federated Learning. arXiv preprint arXiv:1902.11175 (2019). [53] Pengchao Han, Shiqiang Wang, and Kin K. Leung. 2020. Adaptive Gradient Sparsification for Efficient Federated Learning: An Online Learning Approach. arXiv:2001.04756 [cs.LG] [54] Yufei Han and Xiangliang Zhang. 2019. Robust Federated Training via Collaborative Machine Teaching using Trusted Instances. arXiv preprint arXiv:1905.02941 (2019). [55] M. Hao, H. Li, X. Luo, G. Xu, H. Yang, and S. Liu. 2019. Efficient and Privacy-enhanced Federated Learning for Industrial Artificial Intelligence. IEEE Transactions on Industrial Informatics (2019), 1–1. [56] M. Hao, H. Li, G. Xu, S. Liu, and H. Yang. 2019. Towards Efficient and Privacy-Preserving Federated Deep Learning. In ICC 2019 - 2019 IEEE International Conference on Communications (ICC). 1–6. [57] Andrew Hard, Kanishka Rao, Rajiv Mathews, Swaroop Ramaswamy, Françoise Beaufays, Sean Augenstein, Hubert Eichner, Chloé Kiddon, and Daniel Ramage. 2018. Federated learning for mobile keyboard prediction. arXiv preprint arXiv:1811.03604 (2018). [58] Stephen Hardy, Wilko Henecka, Hamish Ivey-Law, Richard Nock, Giorgio Patrini, Guillaume Smith, and Brian Thorne. 2017. Private federated learning on vertically partitioned data via entity resolution and additively homomorphic encryption. arXiv preprint arXiv:1711.10677 (2017). [59] Chaoyang He, Conghui Tan, Hanlin Tang, Shuang Qiu, and Ji Liu. 2019. Central server free federated learning over single-sided trust social networks. arXiv preprint arXiv:1910.04956 (2019). [60] X. He, Q. Ling, and T. Chen. 2019. Byzantine-Robust Stochastic Gradient Descent for Distributed Low-Rank Matrix Completion, In 2019 IEEE Data Science Workshop (DSW). 2019 IEEE Data Science Workshop (DSW), 322–326. [61] Tzu-Ming Harry Hsu, Hang Qi, and Matthew Brown. 2019. Measuring the Effects of Non-Identical Data Distribution for Federated Visual Classification. arXiv:1909.06335 [cs.LG] [62] B. Hu, Y. Gao, L. Liu, and H. Ma. 2018. Federated Region-Learning: An Edge Computing Based Framework for Urban Environment Sensing. In 2018 IEEE Global Communications Conference (GLOBECOM). 1–7. [63] Chenghao Hu, Jingyan Jiang, and Zhi Wang. 2019. Decentralized Federated Learning: A Segmented Gossip Approach. arXiv preprint arXiv:1908.07782 (2019). [64] Yao Hu, Xiaoyan Sun, Yang Chen, and Zishuai Lu. 2019. Model and Feature Aggregation Based Federated Learning for Multi-sensor Time Series Trend Following. Springer International Publishing, Cham, 233–246. [65] S. Hua, K. Yang, and Y. Shi. 2019. On-Device Federated Learning via Second-Order Optimization with Over-the-Air Computation. In 2019 IEEE 90th Vehicular Technology Conference (VTC2019-Fall). 1–5. [66] Li Huang, Andrew L. Shea, Huining Qian, Aditya Masurkar, Hao Deng, and Dianbo Liu. 2019. Patient clustering improves efficiency of federated machine learning to predict mortality and hospital stay time using distributed electronic medical records. Journal of Biomedical Informatics 99 (2019), 103291. http://www.sciencedirect.com/ science/article/pii/S1532046419302102 [67] Amir Jalalirad, Marco Scavuzzo, Catalin Capota, and Michael Sprague. 2019. A Simple and Efficient Federated Recommender System. In Proceedings of the 6th IEEE/ACM International Conference on Big Data Computing, Applications and Technologies. Association for Computing Machinery, Auckland, New Zealand, 53–58. [68] Eunjeong Jeong, Seungeun Oh, Hyesung Kim, Jihong Park, Mehdi Bennis, and Seong-Lyun Kim. 2018. Communicationefficient on-device machine learning: Federated distillation and augmentation under non-iid private data. arXiv preprint arXiv:1811.11479 (2018).

J. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2020.

A Systematic Literature Review on Federated Machine Learning: From A Software Engineering Perspective

111:33

[69] Shaoxiong Ji, Guodong Long, Shirui Pan, Tianqing Zhu, Jing Jiang, and Sen Wang. 2019. Detecting Suicidal Ideation with Data Protection in Online Communities. Springer International Publishing, Cham, 225–229.
[70] Di Jiang, Yuanfeng Song, Yongxin Tong, Xueyang Wu, Weiwei Zhao, Qian Xu, and Qiang Yang. 2019. Federated Topic Modeling. In Proceedings of the 28th ACM International Conference on Information and Knowledge Management. Association for Computing Machinery, Beijing, China, 1071–1080.
[71] Yihan Jiang, Jakub Konečny`, Keith Rush, and Sreeram Kannan. 2019. Improving federated learning personalization via model agnostic meta learning. arXiv preprint arXiv:1909.12488 (2019).
[72] Yuang Jiang, Shiqiang Wang, Bong Jun Ko, Wei-Han Lee, and Leandros Tassiulas. 2019. Model Pruning Enables Efficient Federated Learning on Edge Devices. arXiv preprint arXiv:1909.12326 (2019).
[73] Peter Kairouz, H. Brendan McMahan, Brendan Avent, Aurélien Bellet, Mehdi Bennis, Arjun Nitin Bhagoji, Keith Bonawitz, Zachary Charles, Graham Cormode, Rachel Cummings, Rafael G. L. D’Oliveira, Salim El Rouayheb, David Evans, Josh Gardner, Zachary Garrett, Adrià Gascón, Badih Ghazi, Phillip B. Gibbons, Marco Gruteser, Zaid Harchaoui, Chaoyang He, Lie He, Zhouyuan Huo, Ben Hutchinson, Justin Hsu, Martin Jaggi, Tara Javidi, Gauri Joshi, Mikhail Khodak, Jakub Konečný, Aleksandra Korolova, Farinaz Koushanfar, Sanmi Koyejo, Tancrède Lepoint, Yang Liu, Prateek Mittal, Mehryar Mohri, Richard Nock, Ayfer Özgür, Rasmus Pagh, Mariana Raykova, Hang Qi, Daniel Ramage, Ramesh Raskar, Dawn Song, Weikang Song, Sebastian U. Stich, Ziteng Sun, Ananda Theertha Suresh, Florian Tramèr, Praneeth Vepakomma, Jianyu Wang, Li Xiong, Zheng Xu, Qiang Yang, Felix X. Yu, Han Yu, and Sen Zhao. 2019. Advances and Open Problems in Federated Learning. arXiv:1912.04977 [cs.LG]
[74] J. Kang, Z. Xiong, D. Niyato, S. Xie, and J. Zhang. 2019. Incentive Mechanism for Reliable Federated Learning: A Joint Optimization Approach to Combining Reputation and Contract Theory. IEEE Internet of Things Journal 6, 6 (Dec 2019), 10700–10714.
[75] J. Kang, Z. Xiong, D. Niyato, H. Yu, Y. Liang, and D. I. Kim. 2019. Incentive Design for Efficient Federated Learning in Mobile Networks: A Contract Theory Approach. In 2019 IEEE VTS Asia Pacific Wireless Communications Symposium (APWCS). 1–5.
[76] J. Kang, Z. Xiong, D. Niyato, Y. Zou, Y. Zhang, and M. Guizani. 2020. Reliable Federated Learning for Mobile Networks. IEEE Wireless Communications 27, 2 (2020), 72–80.
[77] Sai Praneeth Karimireddy, Satyen Kale, Mehryar Mohri, Sashank J Reddi, Sebastian U Stich, and Ananda Theertha Suresh. 2019. SCAFFOLD: Stochastic controlled averaging for on-device federated learning. arXiv preprint arXiv:1910.06378 (2019).
[78] Latif U Khan, Nguyen H Tran, Shashi Raj Pandey, Walid Saad, Zhu Han, Minh NH Nguyen, and Choong Seon Hong. 2019. Federated Learning for Edge Networks: Resource Optimization and Incentive Mechanism. arXiv preprint arXiv:1911.05642 (2019).
[79] H. Kim, J. Park, M. Bennis, and S. Kim. 2019. Blockchained On-Device Federated Learning. IEEE Communications Letters (2019), 1–1.
[80] Y. J. Kim and C. S. Hong. 2019. Blockchain-based Node-aware Dynamic Weighting Methods for Improving Federated Learning Performance. In 2019 20th Asia-Pacific Network Operations and Management Symposium (APNOMS). 1–4.
[81] B. Kitchenham and S Charters. 2007. Guidelines for performing Systematic Literature Reviews in Software Engineering.
[82] Jakub Konečny`, H Brendan McMahan, Felix X Yu, Peter Richtárik, Ananda Theertha Suresh, and Dave Bacon. 2016. Federated learning: Strategies for improving communication efficiency. arXiv preprint arXiv:1610.05492 (2016).
[83] Jakub Konečný, H. Brendan McMahan, Daniel Ramage, and Peter Richtárik. 2016. Federated Optimization: Distributed Machine Learning for On-Device Intelligence. arXiv:1610.02527 [cs.LG]
[84] Antti Koskela and Antti Honkela. 2019. Learning Rate Adaptation for Federated and Differentially Private Learning. stat 1050 (2019), 31.
[85] Anusha Lalitha, Osman Cihan Kilinc, Tara Javidi, and Farinaz Koushanfar. 2019. Peer-to-peer Federated Learning on Graphs. arXiv preprint arXiv:1901.11173 (2019).
[86] Anusha Lalitha, Shubhanshu Shekhar, Tara Javidi, and Farinaz Koushanfar. 2018. Fully decentralized federated learning. In Third workshop on Bayesian Deep Learning (NeurIPS).
[87] Anusha Lalitha, Xinghan Wang, Osman Kilinc, Yongxi Lu, Tara Javidi, and Farinaz Koushanfar. 2019. Decentralized Bayesian Learning over Graphs. arXiv:1905.10466 [stat.ML]
[88] D. Leroy, A. Coucke, T. Lavril, T. Gisselbrecht, and J. Dureau. 2019. Federated Learning for Keyword Spotting. In ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). 6341–6345.
[89] Daliang Li and Junpu Wang. 2019. FedMD: Heterogenous Federated Learning via Model Distillation. arXiv preprint arXiv:1910.03581 (2019).
[90] Hongyu Li and Tianqi Han. 2019. An End-to-End Encrypted Neural Network for Gradient Updates Transmission in Federated Learning. arXiv:1908.08340 [cs.LG]

J. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2020.

111:34

Lo, et al.

[91] Jeffrey Li, Mikhail Khodak, Sebastian Caldas, and Ameet Talwalkar. 2019. Differentially Private Meta-Learning. arXiv:1909.05830 [cs.LG]
[92] L. Li, H. Xiong, Z. Guo, J. Wang, and C. Xu. 2019. SmartPC: Hierarchical Pace Control in Real-Time Federated Learning System, In 2019 IEEE Real-Time Systems Symposium (RTSS). 2019 IEEE Real-Time Systems Symposium (RTSS), 406–418.
[93] Qinbin Li, Zeyi Wen, Zhaomin Wu, Sixu Hu, Naibo Wang, and Bingsheng He. 2019. A Survey on Federated Learning Systems: Vision, Hype and Reality for Data Privacy and Protection. arXiv:1907.09693 [cs.LG]
[94] Suyi Li, Yong Cheng, Yang Liu, Wei Wang, and Tianjian Chen. 2019. Abnormal client behavior detection in federated learning. arXiv preprint arXiv:1910.09933 (2019).
[95] Tian Li, Anit Kumar Sahu, Ameet Talwalkar, and Virginia Smith. 2020. Federated Learning: Challenges, Methods, and Future Directions. IEEE Signal Processing Magazine 37, 3 (May 2020), 50–60. https://doi.org/10.1109/msp.2020.2975749
[96] Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and Virginia Smith. 2018. Federated Optimization in Heterogeneous Networks. arXiv:1812.06127 [cs.LG]
[97] Tian Li, Maziar Sanjabi, and Virginia Smith. 2019. Fair Resource Allocation in Federated Learning. arXiv preprint arXiv:1905.10497 (2019).
[98] Wei Yang Bryan Lim, Nguyen Cong Luong, Dinh Thai Hoang, Yutao Jiao, Ying-Chang Liang, Qiang Yang, Dusit Niyato, and Chunyan Miao. 2019. Federated Learning in Mobile Edge Networks: A Comprehensive Survey. arXiv:1909.11875 [cs.NI]
[99] B. Liu, L. Wang, and M. Liu. 2019. Lifelong Federated Reinforcement Learning: A Learning Architecture for Navigation in Cloud Robotic Systems. IEEE Robotics and Automation Letters 4, 4 (Oct 2019), 4555–4562.
[100] Changchang Liu, Supriyo Chakraborty, and Dinesh Verma. 2019. Secure Model Fusion for Distributed Learning Using Partial Homomorphic Encryption. In Policy-Based Autonomic Data Governance, Seraphin Calo, Elisa Bertino, and Dinesh Verma (Eds.). Springer International Publishing, Cham, 154–179. https://doi.org/10.1007/978-3-030-17277-0_9
[101] Lumin Liu, Jun Zhang, S. H. Song, and Khaled Ben Letaief. 2019. client-edge-cloud hierarchical federated learning. CoRR abs/1905.06641 (2019). arXiv:1905.06641 http://arxiv.org/abs/1905.06641
[102] Yang Liu, Tianjian Chen, and Qiang Yang. 2018. Secure Federated Transfer Learning. arXiv:1812.03337 [cs.LG] [103] Yang Liu, Yan Kang, Xinwei Zhang, Liping Li, Yong Cheng, Tianjian Chen, Mingyi Hong, and Qiang Yang. 2019. A
Communication Efficient Vertical Federated Learning Framework. arXiv preprint arXiv:1912.11187 (2019). [104] Yang Liu, Zhuo Ma, Ximeng Liu, Siqi Ma, Surya Nepal, and Robert Deng. 2019. Boosting Privately: Privacy-Preserving
Federated Extreme Boosting for Mobile Crowdsensing. arXiv:1907.10218 [cs.CR] [105] Y. Lu, X. Huang, Y. Dai, S. Maharjan, and Y. Zhang. 2019. Blockchain and Federated Learning for Privacy-preserved
Data Sharing in Industrial IoT. IEEE Transactions on Industrial Informatics (2019), 1–1. [106] Y. Lu, X. Huang, Y. Dai, S. Maharjan, and Y. Zhang. 2019. Differentially Private Asynchronous Federated Learning for
Mobile Edge Computing in Urban Informatics. IEEE Transactions on Industrial Informatics (2019), 1–1. [107] S. Lugan, P. Desbordes, E. Brion, L. X. Ramos Tormo, A. Legay, and B. Macq. 2019. Secure Architectures Implementing
Trusted Coalitions for Blockchained Distributed Learning (TCLearn). IEEE Access 7 (2019), 181789–181799. [108] Lingjuan Lyu, Han Yu, and Qiang Yang. 2020. Threats to Federated Learning: A Survey. arXiv:2003.02133 [cs.CR] [109] Jing Ma, Qiuchen Zhang, Jian Lou, Joyce C. Ho, Li Xiong, and Xiaoqian Jiang. 2019. Privacy-Preserving Tensor
Factorization for Collaborative Health Data Analysis. In Proceedings of the 28th ACM International Conference on Information and Knowledge Management. Association for Computing Machinery, Beijing, China, 1291–1300. [110] U. Majeed and C. S. Hong. 2019. FLchain: Federated Learning via MEC-enabled Blockchain Network. In 2019 20th Asia-Pacific Network Operations and Management Symposium (APNOMS). 1–4. [111] Kalikinkar Mandal and Guang Gong. 2019. PrivFL: Practical Privacy-preserving Federated Regressions on Highdimensional Data over Mobile Networks. In Proceedings of the 2019 ACM SIGSAC Conference on Cloud Computing Security Workshop. Association for Computing Machinery, London, United Kingdom, 57–68. [112] I. Martinez, S. Francis, and A. S. Hafid. 2019. Record and Reward Federated Learning Contributions with Blockchain. In 2019 International Conference on Cyber-Enabled Distributed Computing and Knowledge Discovery (CyberC). 50–57. [113] H. Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Agüera y Arcas. 2016. CommunicationEfficient Learning of Deep Networks from Decentralized Data. arXiv:1602.05629 [cs.LG] [114] J. Mills, J. Hu, and G. Min. 2019. Communication-Efficient Federated Learning for Wireless Edge Intelligence in IoT. IEEE Internet of Things Journal (2019), 1–1. [115] Fan Mo and Hamed Haddadi. [n.d.]. Efficient and Private Federated Learning using TEE. ([n. d.]). [116] Mehryar Mohri, Gary Sivek, and Ananda Theertha Suresh. 2019. Agnostic federated learning. arXiv preprint arXiv:1902.00146 (2019). [117] N. I. Mowla, N. H. Tran, I. Doh, and K. Chae. 2020. Federated Learning-Based Cognitive Detection of Jamming Attack in Flying Ad-Hoc Network. IEEE Access 8 (2020), 4338–4350.

J. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2020.

A Systematic Literature Review on Federated Machine Learning: From A Software Engineering Perspective

111:35

[118] C. Nadiger, A. Kumar, and S. Abdelhak. 2019. Federated Reinforcement Learning for Fast Personalization. In 2019 IEEE Second International Conference on Artificial Intelligence and Knowledge Engineering (AIKE). 123–127.
[119] T. D. Nguyen, S. Marchal, M. Miettinen, H. Fereidooni, N. Asokan, and A. Sadeghi. 2019. DÏoT: A Federated Selflearning Anomaly Detection System for IoT. In 2019 IEEE 39th International Conference on Distributed Computing Systems (ICDCS). 756–767.
[120] Solmaz Niknam, Harpreet S. Dhillon, and Jeffery H. Reed. 2019. Federated Learning for Wireless Communications: Motivation, Opportunities and Challenges. arXiv:1908.06847 [eess.SP]
[121] T. Nishio and R. Yonetani. 2019. Client Selection for Federated Learning with Heterogeneous Resources in Mobile Edge. In ICC 2019 - 2019 IEEE International Conference on Communications (ICC). 1–7.
[122] Chaoyue Niu, Fan Wu, Shaojie Tang, Lifeng Hua, Rongfei Jia, Chengfei Lv, Zhihua Wu, and Guihai Chen. 2019. Secure federated submodel learning. arXiv preprint arXiv:1911.02254 (2019).
[123] Richard Nock, Stephen Hardy, Wilko Henecka, Hamish Ivey-Law, Giorgio Patrini, Guillaume Smith, and Brian Thorne. 2018. Entity Resolution and Federated Learning get a Federated Resolution. arXiv preprint arXiv:1803.04035 (2018).
[124] Tribhuvanesh Orekondy, Seong Joon Oh, Yang Zhang, Bernt Schiele, and Mario Fritz. 2018. Gradient-Leaks: Understanding and Controlling Deanonymization in Federated Learning. arXiv:1805.05838 [cs.CR]
[125] S. R. Pandey, N. H. Tran, M. Bennis, Y. K. Tun, Z. Han, and C. S. Hong. 2019. Incentivize to Build: A Crowdsourcing Framework for Federated Learning, In 2019 IEEE Global Communications Conference (GLOBECOM). 2019 IEEE Global Communications Conference (GLOBECOM), 1–6.
[126] S. R. Pandey, N. H. Tran, M. Bennis, Y. K. Tun, A. Manzoor, and C. S. Hong. 2020. A Crowdsourcing Framework for On-Device Federated Learning. IEEE Transactions on Wireless Communications 19, 5 (2020), 3241–3256.
[127] Xingchao Peng, Zijun Huang, Yizhe Zhu, and Kate Saenko. 2019. Federated Adversarial Domain Adaptation. arXiv:1911.02054 [cs.CV]
[128] Daniel Peterson, Pallika Kanani, and Virendra J Marathe. 2019. Private Federated Learning with Domain Adaptation. arXiv preprint arXiv:1912.06733 (2019).
[129] Krishna Pillutla, Sham M Kakade, and Zaid Harchaoui. 2019. Robust aggregation for federated learning. arXiv preprint arXiv:1912.13445 (2019).
[130] Davy Preuveneers, Vera Rimmer, Ilias Tsingenopoulos, Jan Spooren, Wouter Joosen, and Elisabeth Ilie-Zudor. 2018. Chained anomaly detection models for federated learning: an intrusion detection case study. Applied Sciences 8, 12 (2018), 2663.
[131] J. Qian, S. P. Gochhayat, and L. K. Hansen. 2019. Distributed Active Learning Strategies on Edge Computing. In
2019 6th IEEE International Conference on Cyber Security and Cloud Computing (CSCloud)/ 2019 5th IEEE International Conference on Edge Computing and Scalable Cloud (EdgeCom). 221–226. [132] Jia Qian, Sayantan Sengupta, and Lars Kai Hansen. 2019. Active Learning Solution on Distributed Edge Computing. arXiv:1906.10718 [cs.DC] [133] Yongfeng Qian, Long Hu, Jing Chen, Xin Guan, Mohammad Mehedi Hassan, and Abdulhameed Alelaiwi. 2019. Privacy-aware service placement for mobile edge computing via federated learning. Information Sciences 505 (2019), 562 – 570. http://www.sciencedirect.com/science/article/pii/S0020025519306814 [134] Swaroop Ramaswamy, Rajiv Mathews, Kanishka Rao, and Françoise Beaufays. 2019. Federated learning for emoji prediction in a mobile keyboard. arXiv preprint arXiv:1906.04329 (2019). [135] Amirhossein Reisizadeh, Aryan Mokhtari, Hamed Hassani, Ali Jadbabaie, and Ramtin Pedarsani. 2019. Fedpaq: A communication-efficient federated learning method with periodic averaging and quantization. arXiv preprint arXiv:1909.13014 (2019). [136] J. Ren, H. Wang, T. Hou, S. Zheng, and C. Tang. 2019. Federated Learning-Based Computation Offloading Optimization in Edge Computing-Supported Internet of Things. IEEE Access 7 (2019), 69194–69201. [137] Jinke Ren, Guanding Yu, and Guangyao Ding. 2019. Accelerating DNN Training in Wireless Federated Edge Learning System. arXiv:1905.09712 [cs.LG] [138] Abhijit Guha Roy, Shayan Siddiqui, Sebastian Pölsterl, Nassir Navab, and Christian Wachinger. 2019. BrainTorrent: A Peer-to-Peer Environment for Decentralized Federated Learning. arXiv preprint arXiv:1905.06731 (2019). [139] Theo Ryffel, Andrew Trask, Morten Dahl, Bobby Wagner, Jason Mancuso, Daniel Rueckert, and Jonathan PasseratPalmbach. 2018. A generic framework for privacy preserving deep learning. arXiv:1811.04017 [cs.LG] [140] Y. Sarikaya and O. Ercetin. 2019. Motivating Workers in Federated Learning: A Stackelberg Game Perspective. IEEE Networking Letters (2019), 1–1. [141] Felix Sattler, Klaus-Robert Müller, and Wojciech Samek. 2019. Clustered Federated Learning: Model-Agnostic Distributed Multi-Task Optimization under Privacy Constraints. arXiv preprint arXiv:1910.01991 (2019). [142] F. Sattler, S. Wiedemann, K. Müller, and W. Samek. 2019. Robust and Communication-Efficient Federated Learning From Non-i.i.d. Data. IEEE Transactions on Neural Networks and Learning Systems (2019), 1–14.

J. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2020.

111:36

Lo, et al.

[143] S. Savazzi, M. Nicoli, and V. Rampa. 2020. Federated Learning with Cooperating Devices: A Consensus Approach for Massive IoT Networks. IEEE Internet of Things Journal (2020), 1–1.
[144] Muhammad Shayan, Clement Fung, Chris J. M. Yoon, and Ivan Beschastnikh. 2018. Biscotti: A Ledger for Private and Secure Peer-to-Peer Machine Learning. arXiv:1811.09904 [cs.LG]
[145] Micah J. Sheller, G. Anthony Reina, Brandon Edwards, Jason Martin, and Spyridon Bakas. 2019. Multi-institutional Deep Learning Modeling Without Sharing Patient Data: A Feasibility Study on Brain Tumor Segmentation. Springer International Publishing, Cham, 92–104.
[146] Shihao Shen, Yiwen Han, Xiaofei Wang, and Yan Wang. 2019. Computation Offloading with Multiple Agents in Edge-Computing–Supported IoT. ACM Trans. Sen. Netw. 16, 1 (2019), Article 8.
[147] Wenqi Shi, Sheng Zhou, and Zhisheng Niu. 2019. Device Scheduling with Fast Convergence for Wireless Federated Learning. arXiv preprint arXiv:1911.00856 (2019).
[148] S. Silva, B. A. Gutman, E. Romero, P. M. Thompson, A. Altmann, and M. Lorenzi. 2019. Federated Learning in Distributed Medical Databases: Meta-Analysis of Large-Scale Subcortical Brain Data. In 2019 IEEE 16th International Symposium on Biomedical Imaging (ISBI 2019). 270–274.
[149] Virginia Smith, Chao-Kai Chiang, Maziar Sanjabi, and Ameet Talwalkar. 2017. Federated multi-task learning. In Proceedings of the 31st International Conference on Neural Information Processing Systems. Curran Associates Inc., Long Beach, California, USA, 4427–4437.
[150] Chunhe Song, Tong Li, Xu Huang, Zhongfeng Wang, and Peng Zeng. 2019. Towards Edge Computing Based Distributed Data Analytics Framework in Smart Grids. Springer International Publishing, Cham, 283–292.
[151] K. Sozinov, V. Vlassov, and S. Girdzijauskas. 2018. Human Activity Recognition Using Federated Learning. In 2018 IEEE Intl Conf on Parallel Distributed Processing with Applications, Ubiquitous Computing Com-
munications, Big Data Cloud Computing, Social Computing Networking, Sustainable Computing Communications (ISPA/IUCC/BDCloud/SocialCom/SustainCom). 1103–1111. [152] Xudong Sun, Andrea Bommert, Florian Pfisterer, Jörg Rähenfürher, Michel Lang, and Bernd Bischl. 2020. High Dimensional Restrictive Federated Model Selection with Multi-objective Bayesian Optimization over Shifted Distributions. In Intelligent Systems and Applications, Yaxin Bi, Rahul Bhatia, and Supriya Kapoor (Eds.). Springer International Publishing, Cham, 629–647. [153] Yuxuan Sun, Sheng Zhou, and Deniz Gündüz. 2019. Energy-Aware Analog Aggregation for Federated Learning with Redundant Data. arXiv preprint arXiv:1911.00188 (2019). [154] Manoj A Thomas, Diya Suzanne Abraham, and Dapeng Liu. 2018. Federated Machine Learning for Translational Research. AMCIS2018 (2018). [155] Aleksei Triastcyn and Boi Faltings. 2019. Federated Generative Privacy. arXiv:1910.08385 [stat.ML] [156] Aleksei Triastcyn and Boi Faltings. 2019. Federated Learning with Bayesian Differential Privacy. arXiv preprint arXiv:1911.10071 (2019). [157] M. Troglia, J. Melcher, Y. Zheng, D. Anthony, A. Yang, and T. Yang. 2019. FaIR: Federated Incumbent Detection in CBRS Band. In 2019 IEEE International Symposium on Dynamic Spectrum Access Networks (DySPAN). 1–6. [158] Stacey Truex, Nathalie Baracaldo, Ali Anwar, Thomas Steinke, Heiko Ludwig, Rui Zhang, and Yi Zhou. 2019. A Hybrid Approach to Privacy-Preserving Federated Learning. In Proceedings of the 12th ACM Workshop on Artificial Intelligence and Security. Association for Computing Machinery, London, United Kingdom, 1–11. [159] Gregor Ulm, Emil Gustavsson, and Mats Jirstrand. 2019. Functional Federated Learning in Erlang (ffl-erl). Springer International Publishing, Cham, 162–178. [160] D. Verma, G. White, and G. de Mel. 2019. Federated AI for the Enterprise: A Web Services Based Implementation. In 2019 IEEE International Conference on Web Services (ICWS). 20–27. [161] Dinesh C Verma, Graham White, Simon Julier, Stepehen Pasteris, Supriyo Chakraborty, and Greg Cirincione. 2019. Approaches to address the data skew problem in federated learning. In Artificial Intelligence and Machine Learning for Multi-Domain Operations Applications, Vol. 11006. International Society for Optics and Photonics, 110061I. [162] Tung T Vu, Duy T Ngo, Nguyen H Tran, Hien Quoc Ngo, Minh N Dao, and Richard H Middleton. 2019. Cell-Free Massive MIMO for Wireless Federated Learning. arXiv preprint arXiv:1909.12567 (2019). [163] Z. Wan, X. Xia, D. Lo, and G. C. Murphy. 2019. How does Machine Learning Change Software Development Practices? IEEE Transactions on Software Engineering (2019), 1–1. [164] Guan Wang. 2019. Interpret Federated Learning with Shapley Values. arXiv preprint arXiv:1905.04519 (2019). [165] Guan Wang, Charlie Xiaoqian Dang, and Ziye Zhou. 2019. Measure Contribution of Participants in Federated Learning. arXiv preprint arXiv:1909.08525 (2019). [166] Kangkang Wang, Rajiv Mathews, Chloé Kiddon, Hubert Eichner, Françoise Beaufays, and Daniel Ramage. 2019. Federated Evaluation of On-device Personalization. arXiv:1910.10252 [cs.LG] [167] L. WANG, W. WANG, and B. LI. 2019. CMFL: Mitigating Communication Overhead for Federated Learning. In 2019 IEEE 39th International Conference on Distributed Computing Systems (ICDCS). 954–964.

J. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2020.

A Systematic Literature Review on Federated Machine Learning: From A Software Engineering Perspective

111:37

[168] S. Wang, T. Tuor, T. Salonidis, K. K. Leung, C. Makaya, T. He, and K. Chan. 2019. Adaptive Federated Learning in Resource Constrained Edge Computing Systems. IEEE Journal on Selected Areas in Communications 37, 6 (June 2019), 1205–1221.
[169] Kang Wei, Jun Li, Ming Ding, Chuan Ma, Howard H. Yang, Farokhi Farhad, Shi Jin, Tony Q. S. Quek, and H. Vincent Poor. 2019. Federated Learning with Differential Privacy: Algorithms and Performance Analysis. arXiv:1911.00222 [cs.LG]
[170] Xiguang Wei, Quan Li, Yang Liu, Han Yu, Tianjian Chen, and Qiang Yang. 2019. Multi-agent visualization for explaining federated learning. In Proceedings of the 28th International Joint Conference on Artificial Intelligence. AAAI Press, 6572–6574.
[171] J. Weng, J. Weng, J. Zhang, M. Li, Y. Zhang, and W. Luo. 2019. DeepChain: Auditable and Privacy-Preserving Deep Learning with Blockchain-based Incentive. IEEE Transactions on Dependable and Secure Computing (2019), 1–1.
[172] Roel Wieringa, Neil Maiden, Nancy Mead, and Colette Rolland. 2005. Requirements Engineering Paper Classification and Evaluation Criteria: A Proposal and a Discussion. Requir. Eng. 11, 1 (Dec. 2005), 102–107. https://doi.org/10. 1007/s00766-005-0021-6
[173] Wentai Wu, Ligang He, Weiwei Lin, Stephen Jarvis, et al. 2019. SAFA: a Semi-Asynchronous Protocol for Fast Federated Learning with Low Overhead. arXiv preprint arXiv:1910.01355 (2019).
[174] Cong Xie, Sanmi Koyejo, and Indranil Gupta. 2019. Asynchronous Federated Optimization. arXiv:1903.03934 [cs.DC] [175] G. Xu, H. Li, S. Liu, K. Yang, and X. Lin. 2020. VerifyNet: Secure and Verifiable Federated Learning. IEEE Transactions
on Information Forensics and Security 15 (2020), 911–926. [176] Jie Xu and Fei Wang. 2019. Federated Learning for Healthcare Informatics. arXiv:1911.06270 [cs.LG] [177] Mengwei Xu, Feng Qian, Qiaozhu Mei, Kang Huang, and Xuanzhe Liu. 2018. DeepType: On-Device Deep Learning for
Input Personalization Service with Minimal Privacy Concern. Proc. ACM Interact. Mob. Wearable Ubiquitous Technol. 2, 4 (2018), Article 197. [178] Runhua Xu, Nathalie Baracaldo, Yi Zhou, Ali Anwar, and Heiko Ludwig. 2019. HybridAlpha: An Efficient Approach for Privacy-Preserving Federated Learning. In Proceedings of the 12th ACM Workshop on Artificial Intelligence and Security. Association for Computing Machinery, London, United Kingdom, 13–23. [179] Zichen Xu, Li Li, and Wenting Zou. 2019. Exploring federated learning on battery-powered devices. In Proceedings of the ACM Turing Celebration Conference - China. Association for Computing Machinery, Chengdu, China, Article 6. [180] Howard H Yang, Ahmed Arafa, Tony QS Quek, and H Vincent Poor. 2019. Age-Based Scheduling Policy for Federated Learning in Mobile Edge Networks. arXiv preprint arXiv:1910.14648 (2019). [181] Kai Yang, Tao Fan, Tianjian Chen, Yuanming Shi, and Qiang Yang. 2019. A Quasi-Newton Method Based Vertical Federated Learning Framework for Logistic Regression. arXiv preprint arXiv:1912.00513 (2019). [182] K. Yang, T. Jiang, Y. Shi, and Z. Ding. 2020. Federated Learning via Over-the-Air Computation. IEEE Transactions on Wireless Communications (2020), 1–1. [183] Qiang Yang, Yang Liu, Tianjian Chen, and Yongxin Tong. 2019. Federated Machine Learning: Concept and Applications. ACM Trans. Intell. Syst. Technol. 10, 2, Article 12 (Jan. 2019), 19 pages. https://doi.org/10.1145/3298981 [184] Shengwen Yang, Bing Ren, Xuhui Zhou, and Liping Liu. 2019. Parallel Distributed Logistic Regression for Vertical Federated Learning without Third-Party Coordinator. arXiv preprint arXiv:1911.09824 (2019). [185] Timothy Yang, Galen Andrew, Hubert Eichner, Haicheng Sun, Wei Li, Nicholas Kong, Daniel Ramage, and Françoise Beaufays. 2018. Applied federated learning: Improving google keyboard query suggestions. arXiv preprint arXiv:1812.02903 (2018). [186] Wensi Yang, Yuhang Zhang, Kejiang Ye, Li Li, and Cheng-Zhong Xu. 2019. FFD: A Federated Learning Based Method for Credit Card Fraud Detection. Springer International Publishing, Cham, 18–32. [187] Zhaohui Yang, Mingzhe Chen, Walid Saad, Choong Seon Hong, and Mohammad Shikh-Bahaei. 2019. Energy Efficient Federated Learning Over Wireless Communication Networks. arXiv preprint arXiv:1911.02417 (2019). [188] X. Yao, C. Huang, and L. Sun. 2018. Two-Stream Federated Learning: Reduce the Communication Costs. In 2018 IEEE Visual Communications and Image Processing (VCIP). 1–4. [189] X. Yao, T. Huang, C. Wu, R. Zhang, and L. Sun. 2019. Towards Faster and Better Federated Learning: A Feature Fusion Approach. In 2019 IEEE International Conference on Image Processing (ICIP). 175–179. [190] D. Ye, R. Yu, M. Pan, and Z. Han. 2020. Federated Learning in Vehicular Edge Computing: A Selective Model Aggregation Approach. IEEE Access (2020), 1–1. [191] B. Yin, H. Yin, Y. Wu, and Z. Jiang. 2020. FDC: A Secure Federated Deep Learning Mechanism for Data Collaborations in the Internet of Things. IEEE Internet of Things Journal (2020), 1–1. [192] Z. Yu, J. Hu, G. Min, H. Lu, Z. Zhao, H. Wang, and N. Georgalas. 2018. Federated Learning Based Proactive Content Caching in Edge Computing. In 2018 IEEE Global Communications Conference (GLOBECOM). 1–6. [193] Song Guo Yufeng Zhan, Peng Li. 2020. Experience-Driven Computational Resource Allocation of Federated Learning by Deep Reinforcement Learning. IEEE IPDPS (2020).

J. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2020.

111:38

Lo, et al.

[194] Mikhail Yurochkin, Mayank Agarwal, Soumya Ghosh, Kristjan Greenewald, Trong Nghia Hoang, and Yasaman Khazaeni. 2019. Bayesian nonparametric federated learning of neural networks. arXiv preprint arXiv:1905.12022 (2019).
[195] Qunsong Zeng, Yuqing Du, Kin K. Leung, and Kaibin Huang. 2019. Energy-Efficient Radio Resource Allocation for Federated Edge Learning. CoRR abs/1907.06040 (2019). arXiv:1907.06040 http://arxiv.org/abs/1907.06040
[196] Y. Zhan, P. Li, Z. Qu, D. Zeng, and S. Guo. 2020. A Learning-based Incentive Mechanism for Federated Learning. IEEE Internet of Things Journal (2020), 1–1.
[197] Jiale Zhang, Junyu Wang, Yanchao Zhao, and Bing Chen. 2019. An Efficient Federated Learning Scheme with Differential Privacy in Mobile Edge Computing. Springer International Publishing, Cham, 538–550.
[198] X. Zhang, X. Chen, J. Liu, and Y. Xiang. 2019. DeepPAR and DeepDPA: Privacy-Preserving and Asynchronous Deep Learning for Industrial IoT. IEEE Transactions on Industrial Informatics (2019), 1–1.
[199] X. Zhang, M. Peng, S. Yan, and Y. Sun. 2019. Deep Reinforcement Learning Based Mode Selection and Resource Allocation for Cellular V2X Communications. IEEE Internet of Things Journal (2019), 1–1.
[200] Ying Zhao, Junjun Chen, Di Wu, Jian Teng, and Shui Yu. 2019. Multi-Task Network Anomaly Detection using Federated Learning. In Proceedings of the Tenth International Symposium on Information and Communication Technology. Association for Computing Machinery, Hanoi, Ha Long Bay, Viet Nam, 273–279.
[201] Ying Zhao, Junjun Chen, Jiale Zhang, Di Wu, Jian Teng, and Shui Yu. 2020. PDGAN: A Novel Poisoning Defense Method in Federated Learning Using Generative Adversarial Network. In Algorithms and Architectures for Parallel Processing, Sheng Wen, Albert Zomaya, and Laurence T. Yang (Eds.). Springer International Publishing, Cham, 595–609.
[202] Yue Zhao, Meng Li, Liangzhen Lai, Naveen Suda, Damon Civin, and Vikas Chandra. 2018. Federated learning with non-iid data. arXiv preprint arXiv:1806.00582 (2018).
[203] Yang Zhao, Jun Zhao, Linshan Jiang, Rui Tan, and Dusit Niyato. 2019. Mobile Edge Computing, Blockchain and Reputation-based Crowdsourcing IoT Federated Learning: A Secure, Decentralized and Privacy-preserving System. arXiv preprint arXiv:1906.10893 (2019).
[204] P. Zhou, K. Wang, L. Guo, S. Gong, and B. Zheng. 2019. A Privacy-Preserving Distributed Contextual Federated Online Learning Framework with Big Data Support in Social Recommender Systems. IEEE Transactions on Knowledge and Data Engineering (2019), 1–1.
[205] W. Zhou, Y. Li, S. Chen, and B. Ding. 2018. Real-Time Data Processing Architecture for Multi-Robots Based on Differential Federated Learning. In 2018 IEEE SmartWorld, Ubiquitous Intelligence Computing, Advanced Trusted Computing, Scalable Computing Communications, Cloud Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI). 462–471.
[206] G. Zhu, Y. Wang, and K. Huang. 2020. Broadband Analog Aggregation for Low-Latency Federated Edge Learning. IEEE Transactions on Wireless Communications 19, 1 (Jan 2020), 491–506.
[207] H. Zhu and Y. Jin. 2019. Multi-Objective Evolutionary Federated Learning. IEEE Transactions on Neural Networks and Learning Systems (2019), 1–13.
[208] Xudong Zhu, Hui Li, and Yang Yu. 2019. Blockchain-Based Privacy Preserving Deep Learning. Springer International Publishing, Cham, 370–383.
[209] Y. Zou, S. Feng, D. Niyato, Y. Jiao, S. Gong, and W. Cheng. 2019. Mobile Device Training Strategies in Federated Learning: An Evolutionary Game Approach. In 2019 International Conference on Internet of Things (iThings) and IEEE Green Computing and Communications (GreenCom) and IEEE Cyber, Physical and Social Computing (CPSCom) and IEEE Smart Data (SmartData). 874–879.
A APPENDIX
A.1 Data extraction sheet of selected primary studies
https://drive.google.com/file/d/10yYG8W1FW0qVQOru_kMyS86owuKnZPnz/view?usp=sharing

J. ACM, Vol. 37, No. 4, Article 111. Publication date: August 2020.

